
> [!info]
> **Lenker:** [Emneplan](https://www.hvl.no/studier/studieprogram/emne/MAT101)
> **Studiepoeng:** 10
> **Vurdering:** Skoleeksamen, 3.12.2025 kl. 09:00
> **GitHub:** [lzzrhx/studies/01-dataing/dat100](https://github.com/lzzrhx/studies/tree/main/01-dataing/mat101)

>[!todo]
>- [x] Se video - Haskell Programming Full Course
>- [x] Se videospilleliste - Discrete Math (Full Course)
>- [x] Uke 33 - Kap. 1.2, 1.3
>- [x] Uke 34 - Øvelse 1
>- [x] Uke 34 - Kap. 2.1, 2.2, 2.3, 2.4
>- [x] Uke 35 - Kap. 3.1, 3.2, 3.3, 3.4
>- [x] Uke 35 - Øvelse 2
>- [x] Uke 36 - Øvelse 3
>- [x] ==**Frist 12. September - Obligatorisk oppgave 1**==
>- [x] Uke 37 - Øvelse 4
>- [x] Uke 37 - Kap. 6.1, 6.2, 6.3
>- [x] Uke 38 - Kap. 8.1, 8.2, 8.3
>- [ ] Uke 38 - Øvelse 5
>- [ ] Uke 39 - Øvelse 6
>- [ ] Uke 40 - Øvelse 7
>- [x] Uke 39 - Kap. 7.1, 7.2, 7.3
>- [x] Uke 41 - ==Obligatorisk oppgave 2 (frist 10.10)==
>- [x] Uke 41 - Kap. 5.1, 5.2, 5.3
>- [x] Uke 42 - Kap. 5.6, 5.9
>- [ ] Uke 42 - Øvelse 8
>- [x] Uke 43 - Kap. 4.4, 4.5, 8.1, 8.3, 2.5
>- [ ] Uke 43 - Øvelse 9
>- [ ] Uke 44 - ==Obligatorisk oppgave 3 (frist 05.11)==
>- [x] Uke 44 - Kap. 1.4, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6


| Ukenr. | Emne/kapitler i lærebok                                           |
| ------ | ----------------------------------------------------------------- |
| 33     | Å snakke matematisk, delkapitler 1.2, 1.3 +  Haskell intro.       |
| 34     | Logikk, delkapitler 2.1, 2.2, 2.3, 2.4. (==oblig 1 ut==)          |
| 35     | Logikk, kvantorer, delkapitler 3.1, 3.2, 3.3, 3.4.                |
| 36     | Kvantorer                                                         |
| 37     | Mengder, delkapitler 6.1, 6.2, 6.3, kanskje 6.4?                  |
| 38     | Relasjoner, delkapitler 8.1, 8.2, 8.3, 8.5  (==oblig 2 ut)==      |
| 39     | Funksjoner, delkapitler 7.1, 7.2, 7.3, kanskje 7.4.               |
| 40     | Studieuke, bare øvelse                                            |
| 41     | Induksjon, delkapitler 5.1, 5.2, 5.3.                             |
| 42     | Rekursjon,  delkapitler 5.6, 5.9. (==oblig 3 ut==)                |
| 43     | Modulregning og talsystemer, delkapitler 4.4, 4.5, 8.1, 8.3, 2.5. |
| 44     | Grafer, delkapitler 1.4, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6.      |
| 45     | Grafer                                                            |
| 46     | Eksamensforberedelse (==prøveeksamen som oblig 4==)               |
| 47     | Eksamensforberedelse                                              |

**Pensumliste:**
+ [Discrete mathematics with applications (5.utg.)](https://bibsys-xc.alma.exlibrisgroup.com/leganto/public/47BIBSYS_HIB/citation/10380570760002221?auth=SAML)

**Lenker:**
- [(YouTube spilleliste) Trefor Bazett - Discrete Math (Full Course)](https://www.youtube.com/playlist?list=PLHXZ9OQGMqxersk8fUxiUMSIx0DBqsKZS)
- [Discrete Structures for Computing, University of Western Ontario](https://www.csd.uwo.ca/~abrandt5/teaching/DiscreteStructures/)
- [Wikipedia, List of logic symbols](https://www.wikiwand.com/en/articles/List_of_logic_symbols)

**Haskell lenker:**
- [GHCup Haskell Installation](https://www.haskell.org/ghcup/)
- [Haskell Documentation](https://www.haskell.org/documentation/)
- [GHCi Documentation](https://downloads.haskell.org/ghc/latest/docs/users_guide/ghci.html)
- [(Video) Haskell Programming Full Course 2024](https://youtu.be/TklkNLihQ_A)

```
--------------------------------------------------------------------------------
-- Norsk / Engelsk ordliste:
--------------------------------------------------------------------------------
heltall                            integer
boolsk                             boolean
variabel                           variable
uttrykk                            expression
ledd                               term
element                            element
mengde                             set
mengdebygger                       set-builder / set comprehension
delmengde                          subset
union                              union
snitt                              intersection
verdimengde / rekkevidde           range
tuppel                             tuple
funksjon                           function
produkt                            product
kartesisk produkt / kryssprodukt   cartesian product / cross-product
binær relasjon                     binary relation
definisjonsområdet / domene        domain
verdiområdet / kodomene            codomain
funksjon                           function
argument                           argument
utsagn                             statement / proposition
konnektiv / logisk operator        logical connective / logical operator
konjunksjon / og                   conjunction / and
disjunksjon / eller                disjunction / or
negasjon / ikke                    negation / not
unær operasjon                     unary operation
sann                               true
usann                              false
sammensatt utsagn                  compound proposition
sannhetsverdi                      truth value
utsagnsform                        statement form / propositional form
sannhetstabell                     truth table
logisk ekvivalent                  logically equivalent
tautologi                          tautology
selvmotsigelse                     contradiction
eksklusiv eller                    exclusive OR (XOR)
implikasjon                        implication
kontraposisjon                     contraposition
konverse                           converse
inverse                            inverse
bikondisjonal / biimplikasjon      biconditional / biimplication
grunnutsagn                        simple proposition
kontrapositive                     contrapositive
boolsk notasjon                    boolean notation
disjunktiv normalform              disjunctive normal form
injektiv / en-til-en               injective
surjective / på                    surjective
bijektiv                           bijective
sammensetning                      composition
følge                              sequence
predikat                           predicate
sannhetsmengde                     truth set
∀ allkvantor                       universal quantifier
∃ eksistenskvantoren               existential quantifier
bundet variabel                    bounded variable
skopet                             scope


--------------------------------------------------------------------------------
-- Symboler:
--------------------------------------------------------------------------------
∈    \in              element i
∉    \nin             element ikke i
⊆    \subseteq        delmengde
⊂    \subset          ekte delmengde
⊆    \not\subseteq    ikke delmengde av
∅    \emptyset        den tomme mengden
ℕ    \mathbb{N}       mengden av naturlige tall
ℤ    \mathbb{Z}       mengden av alle heltall
ℚ    \mathbb{Q}       mengden av rasjonale tall
-    \mathbb{I}       mengden av irrasjonale tall
ℝ    \mathbb{R}       mengden av reelle tall
{}   \{\}             mengde
⟨⟩   \lange \rangle   tuppel
×    \times           kryssprodukt
≡    \equiv           ekvivalens
≢   \not\equiv       ikke ekvivalens
⊕    \oplus           xor
∧    \land             og (konkjuksjon)
∨    \lor              eller (disjunksjon)
¬    \neg              ikke
~    \sim              ikke
→    \rightarrow       implikasjon
↔    \leftrightarrow   biimplikasjon
⇒   \Rightarrow       logisk konsekvens
⇔   \Leftrightarrow   logisk ekvivalens
⊤    \top              sann
⊥    \bot              usann
T    T                 sann
F    F                 usann
1    1                 sann
0    0                 usann
∀    \forall           allkvantoren
∃    \exists           eksistenskvantoren
∪    \cup              union
∩     \cap             snitt
\     \setminus        minus
∴    \therefore       gyldig argument
|     \mid
mod   \mod
(mod) \pmod
≼     \preceq 

--------------------------------------------------------------------------------
-- Kommandoer:
--------------------------------------------------------------------------------

-- Start Haskell REPL
ghci

-- Kompilere .hs fil:
ghc <filnavn>.hs -o <navn>

```


## Notater fra "Discrete mathematics with applications":
- - -
[[#Chapter 1 - Speaking Mathematically]]
	[[#1.1 - Variables]]
	[[#1.2 - The Language of Sets]]
	[[#1.3 - The Language of Relations and Functions]]
	[[#1.4 - The Language of Graphs]]

[[#Chapter 2 - The Logic of Compound Statements]]
	[[#2.1 - Logical Form and Logical Equivalence]]
	[[#2.2 - Conditional Statements]]
	[[#2.3 - Valid and Invalid Arguments]]
	[[#2.4 - (Application) Digital Logic Circuits]]
	[[#2.5 - Application Number Systems and Circuits for Addition]]

[[#Chapter 3 - The Logic of Quantified Statements]]
	[[#3.1 - Predicates and Quantified Statements I]]
	[[#3.2 - Predicates and Quantified Statements II]]
	[[#3.3 - Statements with Multiple Quantifiers]]
	[[#3.4 - Arguments with Quantified Statements]]

[[#Chapter 4 - Elementary Number Theory and Methods of Proof]]
	[[#4.4 - Direct Proof and Counterexample IV Divisibility]]
	[[#4.5 - Direct Proof and Counterexample V Division into Cases and the Quotient-Remainder Theorem]]

[[#Chapter 5 - Sequences, Mathematical Induction, and Recursion]]
	[[#5.1 - Sequences]]
	[[#5.2 - Mathematical Induction I Proving Formulas]]
	[[#5.3 - Mathematical Induction II Applications]]
	[[#5.6 - Defining Sequences Recursively]]
	[[#5.9 - General Recursive Definitions and Structural Induction]]

[[#Chapter 6 - Set Theory]]
	[[#6.1 - Set Theory - Definitions and the Element Method of Proof]]
	[[#6.2 - Properties of Sets]]
	[[#6.3 - Disproofs and Algebraic Proofs]]

[[#Chapter 7 - Properties of Functions]]
	[[#7.1 - Functions Defined on General Sets]]
	[[#7.2 - One-to-One, Onto, and Inverse Functions]]
	[[#7.3 - Composition of Functions]]

[[#Chapter 8 - Properties of Relations]]
	[[#8.1 - Relations on Sets]]
	[[#8.2 - Reflexivity, Symmetry, and Transitivity]]
	[[#8.3 - Equivalence Relations]]
	[[#8.5 - Partial Order Relations]]

[[#Chapter 10 - Theory of Graphs and Trees]]
	[[#10.1 - Trails, Paths, and Circuits]]
	[[#10.2 - Matrix Representation of Graphs]]
	[[#10.3 - Isomorphisms of Graphs]]
	[[#10.4 - Trees Examples and Basic Properties]]
	[[#10.5 - Rooted Trees]]
	[[#10.6 - Spanning Trees and a Shortest Path Algorithm]]


- - -

### Chapter 1 - Speaking Mathematically:

> Therefore O students study mathematics and do not build without foundations.
> - Leonardo da Vinci (1952-1519)

#### 1.1 - Variables:

**Universal Conditional Statements:**
Universal statements contain some variation of the words "for every" and conditional statements contain versions of the words "if-then". A universal conditional statement is a statement that is both universal and conditional.
"For every animal $a$, if $a$ is a dog, then $a$ is a mammal.

**Universal Existential Statements:**
Universal because the first part says that certain property is true for all objects of a given type, and existential because the second part asserts the existence of something.
"Every real number has an additive inverse."

**Existential Universal Statements:**
First part asserts that a certain object exists and second part says that the object satisfies a certain property for all things of a certain kind.
"There is a positive integer that is less than or equal to every positive integer."


#### 1.2 - The Language of Sets:

"... when we attempt to express in mathematical symbols a condition proposed in words. First, we must understand thoroughly the condition. Second, we must be familiar with the forms of mathematical expression."
\- George Polyá (1987-1985)

The word set was introduced in 1879 by Georg Cantor. A set is a collection of objects. A set is completely determined by what its elements are - not the order in which they might be listed or the fact that some elements might be listen more than once.

**Set-Roster Notation:**
$S = \{1..100\}$
$x = 10$
$y = 200$
$x \in S$ - $x$ is an element of the set $S$
$y \not\in S$ - $y$ is not an element of the set $S$

**Frequently used sets:**
$\mathbb{R}$ - The set of all real numbers
$\mathbb{Z}$ - The set of all integers
$\mathbb{Q}$ - The set of all rational numbers, quotients of integers

Addition of a superscript + or - or the letters nonneg indicates only positive or negative or nonnegative elements of the set.
Ex.: $\mathbb{Z}^+$ is the set of all positive integers

**Set-Builder Notation:**
Let $S$ denote a set and let $P(x)$ be a property that that elements of $S$ may or may not satisfy.
$\{x \in S | P(x)\}$

**Subsets:**
If $A$ and $B$ are sets, then $A$ is called a subset of $B$, written $A \subseteq B$, if and only if, every element of $A$ is also an element of $B$. All sets are subsets of themselves. $A$ is a proper subset of $B$ if, and only if, very element of $A$ is in $B$ but there is at least one element of $B$ that is not in $A$. $A \not\subseteq B$ means that there is at least one element $x$ such that $x \in A$ and $x \notin B$.

**Ordered Pairs:**
Given elements $a$ and $b$, the symbol $(a, b)$ denotes the ordered pair consisting of $a$ and $b$ together with the specification that $a$ is the first element of the pair and $b$ is the second element. Two ordered pairs $(a,b)$ and $(c,d)$ are equal if, and only if, $a = c$ and $b = d$.

**Ordered n-tuples:**
Similar to ordered pairs, but with more elements.
Ex.: An ordered 3-tuple: $(a, b, c)$

**Cartesian Product:**
Given sets $A = \{a, b, c\}$ and $B = \{1, 2, 3\}$ the Cartesian product (also called the Cross-product) $A \times B$ is the set of all ordered 2-tuples $(a,b)$ where $a \in A$ and $b \in B$. $A \times B = \{(a,1),(a,2),(a,3),(b,1),(b,2),(b,3),(c,1),(c,2),(c,3)\}$
Symbolically: $A_1 \times A_2 \times \dots \times A_n = \{ ( a_1, a_2,\dots, a_n ) | a_1 \in A_1, a_2 \in A_2, \dots, a_n \in A_n$\}.


#### 1.3 - The Language of Relations and Functions:

> Mathematics is a language.
> - Josiah Willard Gibbs (1839-1903)

**Relations:**
Let $A$ and $B$ be sets. A relation $R$ from $A$ to $B$ is a subset of $A \times B$. Given an ordered pair $(x,y)$ in $A \times B$, $x$ is related to $y$ by $R$, written $x\ R\ y$, if and only if, $(x,y)$ is in $R$. The set $A$ is called the domain of $R$ and the set $B$ is called its co-domain.
The notation for a relation $R$ may be written symbolically as follows:
$x\ R\ y$ means that $(x, y) \in R$.
The notation $x\ \not R\ y$ means that $x$ is not related to $y$ by $R$:
$x\ \not R\ y$ means that $(x,y) \notin R$.

**Arrow Diagram of a Relation:**
Suppose $R$ is a relation from a set $A$ to a set $B$. Draw an arrow from $x$ to $y$ 
if, and only if, $x\ R\ y$
if, and only if, $(x,y) \in R$
Let $A = {1,2,3}$ and $B = {1,3,5}$ and relations $S$ and $T$ are defined as follows:
For every $(x, y) \in A \times B$,
$(x,y) \in S$ means that $x < y$ ($S$ is a "less than" relation)
$T = \{(2,1),(2,5)\}$.
Arrow diagrams of the relations $S$ and $T$:
![[screenshot_2025-09-01-193431.png]]
These example relations illustrate that is is possible to have several arrows coming out of the same element of $A$ pointing in different directions. Also, it is possible to have an element of $A$ that does not have an arrow coming out of it at all.

**Functions:**
A function $F$ from a set $A$ to a set $B$ is a relation with domain $A$ and co-domain $B$ that satisfies the following properties:
	1\. For every element $x$ in $A$, there is an element $y$ such that $(x,y) \in F$.
	2\. For all elements $x$ in $A$ and $y$ and $z$ in $B$, if $(x,y) \in F$ and $(x,z) \in F$, then $y = z$.
A less formal phrasing of the properties:
	1\. Every element of $A$ is the first element of an ordered pair of $F$.
	2\. No two distinct ordered pairs in $F$ have the same first element.
If $A$ and $B$ are sets and $F$ is a function from $A$ to $B$, then given any element $x$ in $A$, the unique element in $B$ that is related to $x$ by $F$ is denoted $F(x)$, which is read "$F$ of $x$."
Given the function $f$ and the function $g$ with the domain $A$, $f = g$, if, and only if, $f(x) = g(x)$ for all $x$ in $A$.

#### 1.4 - The Language of Graphs

> The whole of mathematics consists in the organization of a series of aids to the imagination in the process of reasoning.
> - Alfred North Whitehead, 1861 - 1947

**Definition of a Graph:**
A graph $G$ consists of two finite sets: a nonempty set $V(G)$ of vertices and a set $E(G)$ of edges, where each edge is associated with a set consisting of either one or two vertices called its endpoints. The correspondence from edges to endpoints is called the edge-endpoint function. An edge with just one endpoint is called a loop, and two or more distinct edges with the same set of endpoints are said to be parallel. And edge is said to connect its endpoints; two vertices that are connected by an edge are called adjacent; and a vertex that is an endpoint of a loop is said to be adjacent to itself. And edge is said to be incident on each of its endpoints, and two edges incident on the same endpoint are called adjacent. A vertex on which no edges are incident is called isolated.

**Directed Graph:**
A directed graph, or digraph, consists of two finite sets: a nonempty set $V(G)$ of vertices and a set $D(G)$ of directed edges, where each is associated with an ordered pair of vertices called its endpoints. If edge $e$ is associated with the pair $(v, w)$ of vertices, then $e$ is said to be the (directed) edge from $v$ to $w$.

**Degree of v:**
Let $G$ be a graph and $v$ a vertex of $G$. The degree of $v$, denoted $deg(v),$ equals the number of edges that are incident on $v,$ with an edge that is a loop counted twice.

**Summary of definitions so far:**
- Ordered pairs can be defined in terms of sets.
- Cartesian products can be defined in terms of ordered pairs.
- Relations can be defined as subsets of Cartesian products.
- Functions can be defined as relations.


- - -

### Chapter 2 - The Logic of Compound Statements:

#### 2.1 - Logical Form and Logical Equivalence:

> Logic is a science of the necessary laws of thought, without which no employment of the understanding and the reason takes place.
> - Immanuel Kant, 1785

**Statement:**
A statement (or proposition) is a sentence that is true or false but not both.

**Compound statements:**
Symbols used to build more complicated logical expressions:
$\sim$ denotes not. $\lnot$ can also be used.
$\land$ denotes and. $\lor$ denotes or.
The order of operations: First $\sim$, then $\land$ / $\lor$.
Translating from English to symbols:
$p$ but $q$ means $p$ and $q$.
neither $p$ nor $q$ means $\sim p$ and $\sim q$.

**Negation:**
If $p$ is a statement variable, the negation of $p$ is "not $p$" or "It is not the case that $p$" and is denoted $\sim p$. It has opposite truth value from $p$: if $p$ is true, $\sim p$ is false; if $p$ is false, $\sim p$ is true.

**Conjunction:**
If $p$ and $q$ are statement variables, the conjunction of $p$ and $q$ is "$p$ and $q$," denoted $p \land q$. It is true when, and only when, both $p$ and $q$ are true. If either $p$ or $q$ is false, or if both are false, $p \land q$ is false.

**Disjunction:**
if $p$ and $q$ are statement variables, the disjunction of $p$ and $q$ is "$p$ or $q$", denoted $p \lor q$. It is true when either $p$ is true, or $q$ is true, or both $p$ and $q$ are true; it is false only when both $p$ and $q$ are false.

**Statement forms:**
A statement form (or propositional form) is an expression made up of statement variables (such as $p$, $q$, and $r$) and logical connectives (such as $\sim$, $\land$, and $\lor$) that becomes a statement when actual statements are substituted for the component statement variables. The truth table for a given statement form displays the truth values that correspond to all possible combinations of truth values for its component statement variables.

**Exclusive or:**
When or is used in its exclusive sense, the statement "$p$ or $q$" means "$p$ or $q$ but not both", which translates into symbols as $(p \lor q) \land \sim (p \land q)$.
Exclusive or can be written with the symbol $\oplus$.

**Exclusive or truth table example:**

| $p$ | $q$ | $p \lor q$ | $p \land q$ | $\sim (p \land q)$ | $(p \lor q) \land \sim (p \land q)$ |
| --- | --- | ---------- | ----------- | ------------------ | ----------------------------------- |
| T   | T   | T          | T           | F                  | F                                   |
| T   | F   | T          | F           | T                  | T                                   |
| F   | T   | T          | F           | T                  | T                                   |
| F   | F   | F          | F           | T                  | F                                   |
The customary order to write truth tables involving two statements: TT, TF, FT, FF.

**Logical Equivalence:**
Two statement forms are called logically equivalent if, and only if, they have identical truth values for each possible substitution of statements for their statement variables. The logical equivalence of statement forms $P$ and $Q$ is denoted by writing $P \equiv Q$. To test whether two statement forms are logically equivalent a truth table can be used. If in each row the truth value of the two truth statements are the same, then they are logically equivalent.
Two statements are logically equivalent if, and only if, they have logically equivalent forms when identical component statement variables are used to replace identical component statements.

**Double negative property:**
$\sim (\sim p) \equiv p$

**Negations of And and Or: De Morgan's Laws:**
The negation of an and statement is logically equivalent to the or statement in which each component is negated.
Symbolically: $\sim (p \land q) \equiv \sim p\ \lor \sim q$
The negation of an or statement is logically equivalent to the and statement in which each component is negated.
Symbolically: $\sim (p \lor q) \equiv \sim p\ \land \sim q$

**Tautologies:**
Ex.: $p\ \lor \sim p$.
A tautology is a statement form that is always true regardless of the truth values of the individual statements substituted for its statement variables. A statement whose form is a tautology is a tautological statement. If $t$ is a tautology then $p \land t \equiv p$ and $p \lor t \equiv t$.

**Contradictions:**
Ex.: $p\ \land \sim p$.
A contradiction is a statement form that is always false regardless of the truth values of the individual statements substituted for its statement variables. A statement whose form is a contradiction is a contradictory statement. If $c$ is a tautology then $p \land c \equiv c$ and $p \lor c \equiv p$.

**Summary of logical Equivalences:**
![[screenshot_2025-09-02-184606.png]]


#### 2.2 - Conditional Statements:

> ... hypotetical reasoning implies the subordination of the real to the realm of the possible ..
> - Jean Piaget, 1972

**Conditional Statements:**
If $p$ and $q$ are statement variables, the conditional of $q$ by $p$ is "If $p$ then $q$" or "$p$ implies $q$" and is denoted $p \rightarrow q$. It is false when $p$ is true and $q$ is false; otherwise it is true. $p \rightarrow q \equiv \sim p \lor q$. We call $p$ the hypothesis (or antecedent) of the conditional and $q$ the conclusion (or consequent). A conditional statement with a false hypothesis is considered true. In expressions that include $\rightarrow$ as well as other logical operators such as $\land$, $\lor$, and $\sim$, the order of operations is that $\rightarrow$ is performed last.

**The Negation of a Conditional Statement:**
The negation of "if $p$ then $q$" is logically equivalent to "$p$ and not $q$."
Symbolically: $\sim ( p \rightarrow q ) \equiv p\ \land \sim q$

**The Contrapositive of a Conditional Statement:**
One of the most fundamental laws of logic is the equivalence between a conditional statement and its contrapositive. The contrapositive of a conditional statement of the form "If $p$ then $q$" is "If $\sim q$ then $\sim p$.
Symbolically: The contrapositive of $p \rightarrow q$ is $\sim q \rightarrow \sim p$.
$p \rightarrow q \equiv \sim q \rightarrow \sim p$

**The Converse and Inverse of a Conditional Statement:**
These two variants of conditional statements are not logically equivalent to the statement. Suppose a conditional statement of the form "If $p$ then $q$" is given. The converse is "If $q$ then $p$." The inverse is "If $\sim p$ then $q$." The converse and the inverse of a conditional statement are logically equivalent to each other.
Symbolically:
The converse of $p \rightarrow q$ is $q \rightarrow p$,
and the inverse of $p \rightarrow q$ is $\sim p \rightarrow \sim q$,
they are logically equivalent: $q \rightarrow p \equiv \sim p \rightarrow \sim q$.

**Biconditional Statements:**
Given statement variables $p$ and $q$, the biconditional of $p$ and $q$ is "$p$ if, and only if, $q$" and is denoted $p \leftrightarrow q$. It is true if both $p$ and $q$ have the same truth values and is false if $p$ and $q$ have opposite truth values.
Symbolically: $p \leftrightarrow q \equiv (p \rightarrow q) \land (q \rightarrow p) \equiv (\sim p \lor q) \land (\sim q \lor p)$.

**Necessary and Sufficient Conditions:**
If $r$ and $s$ are statements:
$r$ is a sufficient condition for $s$ means "if $r$ then $s$" or that the occurrence of $r$ is sufficient to guarantee the occurrence of $s$.
$r$ is a necessary condition for $s$ means "if not $r$ then not $s$" or that if $r$ does not occur, then $s$ cannot occur either.

**Order of Operations for Logical Operators:**
1. $\sim$ is performed is performed first
2. Then $\land$ and $\lor$
3. And finally $\rightarrow$ and $\leftrightarrow$

**Summary of Symbolical Representation for Conditional Statements:**
1. Conditional Statement: $p \rightarrow q \equiv \sim p \lor q$
2. Negation: $\sim ( p \rightarrow q ) \equiv p\ \land \sim q$
3. Contrapositive: $p \rightarrow q \equiv \sim q \rightarrow \sim p$
4. Converse: $p \rightarrow q \not\equiv q \rightarrow p$
5. Inverse: $p \rightarrow q \not\equiv \sim p \rightarrow \sim q$


#### 2.3 - Valid and Invalid Arguments:

> "Contrariwise," continued Tweedledee, "if it was so, it might be; and if it were so, it would be; but as it isn't, it ain't. That's logic.
> - Lewis Carroll, *Through the Looking Glass*

**Arguments:**
An argument is a sequence of statements, and an argument form is a sequence of statement forms. All statements in an argument and all statement forms in an argument form, except for the final one, are called premises (or assumptions or hypotheses). The final statement or statement form is called the conclusion. The symbol $\therefore$, which is read "therefore," is normally placed just before the conclusion. To say an argument form is valid means that no matter what particular statements are substituted for the statement variables in its premises, if the resulting premises are all true, then the conclusion is also true. To say that an argument is valid means that its form is valid. When an argument is valid and its premises are true, the truth of the conclusion is said to be inferred or deduced from the truth of the premises. A truth table can be used to determine validity or invalidity of an argument. We can only be sure that an argument is true when we know that the argument is sound. An argument is called sound if, and only if, it is valid and all its premises are true. An argument that is not sound is called unsound.

**Rules of Inference:**
A rule of inference is a form of argument that is valid. Here are some examples:
1. Modus Ponens
2. Modus Tollens
3. Generalization
4. Specialization
5. Elimination
6. Transitivity
7. Proof by Division into Cases

**Modus Ponens:**
An argument form consisting of two premises and a conclusion is called a syllogism. The first and second premises are called the major premise and minor premise.The most famous form of syllogism in logic is called modus ponens (latin meaning "method of affirming"). It has the following form:
	If Socrates is a man, then Socrates is mortal.
	Socrates is a man.
	$\therefore$ Socrates is mortal.
Or in abstract form:
	If $p$ then $q$
	$p$
	$\therefore q$

**Modus Tollens:**
Modus tollens is Lating meaning "method of denying".
It has the following form:
	If Zeus is human, then Zeus is mortal.
	Zeus is not mortal.
	$\therefore$ Zeus is not human
Or in abstract form:
	If $p$ then $q$.
	$\sim q$
	$\therefore\ \sim p$

**Generalization:**
	$p$
	$\therefore\ p \lor q$

**Specialization:**
	$p \land q$
	$\therefore\ p$

**Elimination:**
	$p \lor q$
	$\sim q$
	$\therefore\ p$

**Transitivity:**
	$p \rightarrow q$
	$q \rightarrow r$
	$\therefore\ p \rightarrow r$

**Proof by Division into Cases:**
	$p \lor q$
	$p \rightarrow r$
	$q \rightarrow r$
	$\therefore\ r$

**Fallacies:**
A fallacy is an error in reasoning that results in an invalid argument. Three common fallacies are:
1. Using ambiguous premises, and treating them as if they were unambiguous
2. Circular reasoning (assuming what is to proved without having derived it from the premises)
3. Jumping to a conclusion (without adequate grounds).

**The Converse Error Fallacy:**
Converse error is also known as the fallacy of affirming the consequent.
	$p \rightarrow q$
	$q$
	$\therefore\ p$

**The Inverse Error Fallacy:**
Inverse error is also known as the fallacy of denying the antecedent.
	$p \rightarrow q$
	$\sim p$
	$\therefore\ \sim q$

**A Valid Argument with a False Premise and a False Conclusion:**
The example argument is valid my modus ponens. But its major premise is false, and so is its conclusion:
	If Spot is a dog, then Spot is eating yoghurt for breakfast.
	Spot is a dog.
	$\therefore$ Spot is eating yoghurt for breakfast.

**An Invalid Argument with True Premises and a True Conclusion:**
The following argument is invalid by the converse error, but has a true conclusion:
	If New York is a big city, then New York has tall buildings.
	New York has tall buildings.
	$\therefore$ New York is a big city.

**Contradiction rule:**
If you can show that the supposition that statement $p$ is false leads logically to a contradiction, then you can conclude that $p$ is true.
	$\sim p \rightarrow c$, where $c$ is a contradiction
	$\therefore p$

**Summary of Rules of Inference:**
![[screenshot_2025-09-02-220743.png]]


#### 2.4 - (Application) Digital Logic Circuits:

> Only connect!
> - E.M. Forster, *Howards End*

Electrical engineers generally use the symbols 1 and 0 rather than T and F to denote true and false values. 0 and 1 are called bits, short for binary digits.

Any variable, such as a statement variable or an input signal, that can take one of only two values is called a Boolean variable. An expression composed of Boolean variables and the connectives $\sim$, $\land$, and $\lor$ is called a Boolean expression.

**Black box:**
A black box is a circuit where the detailed implementation is often ignored while attention is focus on the relation between the input and the output.

**Recognizer:**
A recognizer is a circuit that outputs a 1 for exactly one particular combination of input signals and outputs 0's for all other combinations.
Ex.: $(P \land Q)\ \land \sim R$

**Types of gates:**
- NOT
- AND
- OR
- NAND (AND + NOT)
- NOR (OR + NOT)


#### 2.5 - Application: Number Systems and Circuits for Addition

> Counting in binary is just like counting in decimal if you are all thumbs.
> - Glaser and Way

**Circuits for Computer Addition:**
![[screenshot_2025-09-28-165126.png]]
![[screenshot_2025-09-28-165143.png]]
![[screenshot_2025-09-28-165354.png]]

**8-bit Two's Complement:**
The 8-bit two's complement for an integer $a$ between $-128$ and $127$ is the 8-bit binary representation for $\begin{cases}a & \text{ if } a \geq 0 \\a^8 - |a| &\text{ if } a < 0.\end{cases}$


- - -

### Chapter 3 - The Logic of Quantified Statements:

#### 3.1 - Predicates and Quantified Statements I:

> ... it was not till within the last few years that it has been realized how fundamental any and some are to the very nature of mathematics.
> - A.N. Whitehead (1861-1947)

**Predicate:**
A predicate is a sentence that contains a finite number of variables and becomes a statement when specific values are substituted for the variables. The domain of a predicate variable is the set of all values that may be substituted in place of the variable.

**Truth Set;**
If $P(x)$ is a predicate and $x$ has domain $D$, the truth set of $P(x)$ is the set of all elements of $D$ that make $P(x)$ true when they are substituted for $x$. The truth set of $P(x)$ is denoted: $\{ x \in D\ |\ P(x)\}$
Let $P(x)$ and $Q(x)$ be predicates and suppose the common domain of $x$ is $D$.
The notation $P(x) \Rightarrow Q(x)$ means that every element in the truth set of $P(x)$ is in the truth set of $Q(x)$, or, equivalently, $\forall x, P(x) \rightarrow Q(x)$.
The notation $P(x) \Leftrightarrow Q(x)$ means that $P(x)$ and $Q(x)$ have identical truth sets, or, equivalently, $\forall x , P(x) \leftrightarrow Q(x)$.

**The Universal Quantifier $\forall$:**
Let $Q(x)$ be a predicate and $D$ the domain of $x$. A universal statement is a statement of the form "$\forall x \in D, Q(x)$." It is defined to be true if, and only if, $Q(x)$ is true for each individual $xx$ in $D$. It is defined to be false if, and only if, $Q(x)$ is false for at least one $x$ in $D$. A value for $x$ for which $Q(x)$ is false is called a counterexample to the universal statement.

**The Existential Quantifier $\exists$:**
Let $Q(x)$ be a predicate and $D$ the domain of $x$. An existential statement is a statement of the form "$\exists x \in D$ such that $Q(x)$." It is defined to be true if, and only if, $Q(x)$ is true for at least one $x$ in $D$. It is false if, and only if, $Q(x)$ is false for all $x$ in $D$.

**Universal Conditional Statement:**
It is common to omit explicit identification of the domain of predicate variables in universal conditional statements.
$\forall x$, if $P(x)$ then $Q(x)$.
$\forall x, P(x) \rightarrow Q(x)$


#### 3.2 - Predicates and Quantified Statements II:

> TOUCHSTONE: Stand you both forth now: stroke your chins, and swear by your beards that I am a knave.
> CELIA: By our beards - if we had them - thou art.
> TOUCHSTONE: By my knavery - if I had it - then I were; but if you swear by that that is not, you are not forsworn.
> - William Shakespeare, *As You Like It*

**Negation of a Universal Statement:**
The negation of a statement of the form $\forall x$ in $D, Q(x)$ is logically equivalent to a statement of the form $\exists x$ in $D$ such that $\sim Q (x)$.
Symbolically: $\sim ( \forall x \in D, Q(x) ) \equiv \exists x \in D$ such that $\sim Q(x)$.

**Negation of an Existential Statement:**
The negation of a statement of the form $\exists x$ in $D$ such that $Q(x)$ is logically equivalent to a statement of the form $\forall x$ in $D, \sim Q(x)$.
Symbolically: $\sim ( \exists x \in D$ such that $Q(x)) \equiv \forall x \in D, \sim Q(x)$

**Negation of Universal Conditional Statements:**
$\sim ( \forall x, P(x) \rightarrow Q(x)) \equiv \exists x$ such that $\sim ( P(x) \rightarrow Q(x))$

**Vacuous Truth of Universal Statements:**
When a universal quantifier is used on an empty set, it is called vacuously true or true by default.

**Variants of Universal Conditional Statements:**
Consider a statement of the form $\forall x \in D$, if $P(x)$ then $Q(x)$.
1. Its contrapositive is the statement $\forall x \in D$, if $\sim Q(x)$ then $\sim P(x)$.
2. Its converse is the statement $\forall x \in D$, if $Q(x)$ then $P(x)$.
3. Its inverse is the statement $\forall x \in D$, if $\sim P(X)$ then $\sim Q(x)$
The original statement and its contrapositive are logically equivalent.
The original statement and its converse form are not logically equivalent.
The original statement and its inverse form are not logically equivalent.
The converse and inverse forms of the original statement are logically equivalent.

**Necessary and Sufficient Conditions, Only if:**
- "$\forall x, r(x)$ is a sufficient condition for $s(x)$" means "$\forall x$, if $r(x)$ then $s(x)$."
- "$\forall x, r(x)$ is a necessary condition for $s(x)$" means "$\forall x$, if $\sim r(x)$ then $\sim s(x)$" or, equivalently, "$\forall x$, if $s(x)$ then $r(x)$."
- "$\forall x, r(x)$ only if $s(x)$" means "$\forall x$, if $\sim s(x)$ then $\sim r(x)$" or equivalently, "$\forall x$, if $r(x)$ then $s(x)$."


#### 3.3 - Statements with Multiple Quantifiers:

> It is not enough to have a good mind. The main thing is to use it well.
> - René Descartes

**Interpreting Statements with Two Different Quantifiers:**
In a statement containing both $\forall$ and $\exists$, changing the order of the quantifiers can significantly change the meaning of the statement.
If you want to establish the truth of a statement of the form $\forall x$ in $D, \exists y$ in $E$, such that $P(x, y)$ your challenge is to allow someone else to pick whatever element $x$ in $D$ they wish and then you must find an element $y$ in $E$ that "works" for that particular $x$.
If you want to establish the truth of a statement of the form $\exists x$ in $D$ such that $\forall y$ in $E, P(x, y)$ your job is to find one particular $x$ in $D$ that will "work" no matter what $y$ in $E$ anyone might choose to challenge you with.

**Negations of Statements with Two Different Quantifiers:**
$\sim ( \forall x \in D, \exists y \in E, P(x, y) ) \equiv \exists x \in D, \forall y \in E, \sim P(x, y)$
$\sim ( \exists x \in D, \forall y \in E, P(x, y) ) \equiv \forall x \in D, \exists y \in E, \sim P(x, y)$

**Language of First-Order Logic:**
Taken together, the symbols for quantifiers, variables, predicates, and logical connectives makes up what is known as the language of first-order logic.


#### 3.4 - Arguments with Quantified Statements:

> The only complete safeguard against reasoning ill, is the habit of reasoning well; familiarity with the principles of correct reasoning; and practice in applying those principles.
> - John Stuart Mill

**Universal Instantiation:**
If a property is true of everything in a set, then it is true for any particular thing in the set.

**Universal Modus Ponens:**
$\forall x$, if $P(x)$ then $Q(x)$
$P(a)$ for a particular $a$.
$\therefore Q(a)$.

**Universal Modus Tollens:**
$\forall x$, if $P(x)$ then $Q(x)$.
$\sim Q(a)$, for a particular $a$.
$\therefore \sim P(a)$.

**Converse Error (Quantified Form):**
This is an invalid conclusion:
$\forall x$, if $P(x)$ then $Q(x)$.
$Q(a)$ for a particular $a$.
$\therefore P(a)$.

**Inverse Error (Quantified Form):**
This is an invalid conclusion:
$\forall x$, if $P(x)$ then $Q(x)$.
$\sim P(a)$, for a particular $a$.
$\therefore \sim Q(a)$.

**Universal Transitivity:**
$\forall x P(x) \rightarrow Q(x)$
$\forall x Q(x) \rightarrow R(x)$
$\therefore \forall x P(x) \rightarrow R(x)$


- - -

### Chapter 4 - Elementary Number Theory and Methods of Proof:

#### 4.4 - Direct Proof and Counterexample IV: Divisibility

> The essential quality of a proof is to compel belief.
> - Pierre de Fermat

Number theory is the study of properties of integers.

**Definition of Divisibility:**
If $n$ and $d$ are integers then $n$ is divisible by $d$ if, and only if, $n$ equals $d$ times some integer and $d \neq 0.$
Instead of "$n$ is divisible by $d$," we can say that
	$n$ is a multiple of $d$, or
	$d$ is a factor of $n$, or
	$d$ is a divisor of $n$, or
	$d$ divides $n$.
The notation $d \mid n$ is read "$d$ divides $n$."
Symbolically, if $n$ and $d$ are integers:
	$d \mid n \ \ \Leftrightarrow \ \ \exists$ an integer, say $k$, such that $n = dk$ and $d \neq 0.$

**Nondivisibility:**
The notation $d \nmid n$ is read "$d$ does not divide $n.$"
	For all integers $n$ and $d, \ \ d \nmid n \ \ \Leftrightarrow \frac{n}{d}$ is not an integer.
Since the negation of an existential statement is universal, the definition of nondivisibility can be written formally using the universal quantifier:
	$d \nmid n$ if, and only if, $\forall$ integer $k, n \neq dk$ or $d = 0.$
Example of checking nondivisibility:
	Does $4 \mid 15$?
	No, $\frac{15}{4} = 3,75,$ which is not an integer.

**Properties of Divisibility:**
- If one positive integer divides a second positive integer, then the first is less than or equal to the second
- The only divisors of $1$ are $1$ and $-1.$
- Divisibility is transitive. If one number divides a second and the second number divides a third, then the first number divides the third.

**Prime Numbers and Divisibility:**
An alternative way to define a prime number is to say that an integer  $n > 1$ is prime if, and only if, its only positive integer divisors are $1$ and itself.

**Example of proof: Transitivity of Divisibility:**
For all integers $a, b,$ and $c$, if $a$ divides $b$ and $b$ divides $c,$ then $a$ divides $c.$
Proof:
Suppose $a, b,$ and $c$ are any \[particular but arbitrarily chosen\] integers such that $a$ divides $b$ and $b$ divides $c.$ \[We must show that $a$ divides $c.$\]
By definition of divisibility, $b = ar$ and $c = bs$ for some integers $r$ and $s.$
By substitution $c = bs = (ar)s = a(rs)$
Let $k = rs.$ Then $k$ is an integer since it is a product of integers, and therefore $c = ak$ where $k$ is an integer.
Thus $a$ divides $c$ by definition of divisibility. \[This is what was to be shown.\]

**The Unique Factorization of Integers Theorem:**
Given any integer $n > 1,$ there exist a positive integer $k,$ distinct prime numbers $p_1,\ p_2,\ \dots,\ p_k,$ and positive integers $e_1,\ e_2,\ \dots,\ e_k$ such that $n = p_1^{e_1}\ p_2^{e_2}\ p_3^{e_3}\ \dots\ p_k^{e_k},$ and any other expression for $n$ as a product of prime numbers is identical to this except, perhaps, for the order in which the factors are written.

**Standard Factored Form:**
Given any integer $n > 1$, the standard factored form of $n$ is an expression of the form $n = p_1^{e_1}\ p_2^{e_2}\ p_3^{e_3}\ \dots\ p_k^{e_k},$ where $k$ is a positive integer, $p_1,\ p_2,\ \dots,\ p_k$ are prime numbers, $e_1,\ e_2,\ \dots,\ e_k$ are positive integers, and $p_1 < p_2 < \dots < p_k.$
Example:
	$3300 = 100 \cdot 33 = 4 \cdot 25 \cdot 3 \cdot 11 = 2 \cdot 2 \cdot 5 \cdot 5 \cdot 3 \cdot 11 = 2^2 \cdot 3^1 \cdot 5^2 \cdot 11^1.$


#### 4.5 - Direct Proof and Counterexample V: Division into Cases and the Quotient-Remainder Theorem

> Be especially critical of any statement following the word "obviously."
> - Anna Pell Wheeler, 1883 - 1966

**The Quotient-Remainder Theorem:**
Given any integer $n$ and positive integer $d,$ there exists unique integers $q$ and $r$ such that $n = dq + r$ and $0 \leq r > d.$

**div and mod:**
Given an integer $n$ and a positive integer $d,$
$n \text{ div } d =$ the integer quotient obtained when $n$ is divided by $d.$
$n \text{ mod } d =$ the nonnegative integer remainder obtained when $n$ is divided by $d.$
Symbolically, if $n$ and $d$ are integers and $d > 0,$ then $n \text{ div } d = q$ and $n \text{ mod } d = r \ \ \Leftrightarrow \ \ n = dq + r,$ where $q$ and $r$ are integers and $0 \leq r < d.$
Example:
	Finding $32 \text{ div }9$ and $32 \text{ mod } 9$
	$9 \cdot 1 = 9$
	$9 \cdot 2 = 18$
	$9 \cdot 3 = 27$
	$\cancel{9 \cdot 4 = 36}$ \[The result is over 32.\]
	$32 - 27 = 5$
	$32 = 9 \cdot 3 + 5$
	$32 \text{ div }9 = 3$
	$32 \text{ mod } 9 = 5$


- - -

### Chapter 5 - Sequences, Mathematical Induction, and Recursion:

The main mathematical structure used in the study of repeated processes is the sequence, and the main mathematical tool used to verify conjectures about sequences is mathematical induction.

#### 5.1 - Sequences

> A mathematician, like a painter or poet, is a maker of patterns.
> - G. H. Hardy, *A Mathematician's Apology*, 1940

**Sequences:**
A sequence is a function whose domain us either all the integers between two given integers or all the integers greater than or equal to a given integer.
Finite sequence:
	In the sequence denoted $a_m,\ a_{m+1},\ a_{m+2},\ \dots,\ a_n,$ each individual element $a_k$ (read "$a$ sub $k$") is called a term. The $k$ in $a_k$ is called a subscript or index, $m$ (which may be any integer) is the subscript of the initial term, and $n$ (which must be an integer that is greater than or equal to $m$) is the subscript of the final term.
Infinite sequence:
	The notation $a_m,\ a_{m+1},\ a_{m+2},\ \dots$ denotes and infinite sequence. An explicit formula or general formula for a sequence is a rule that shows how the values of $a_k$ depend on $k.$

**Summation Notation:**
In 1977 the French mathematician Joseph Louis Lagrange introduced the capital Greek letter sigma, $\Sigma,$ to denote the word sum (or summation), and defined the summation notation as follows: If $m$ and $n$ are integers and $m \leq n,$ the symbol $\sum\limits_{k = m}^{n} a_k,$ read the summation from $k$ equals $m$ to $n$ of $a$-sub-$k,$ is the sum of all the terms $a_m,\ a_{m+1},\ a_{m+2}, \dots, a_n.$ We say that $a_m + a_{m+1} + a_{m+2} + \dots + a_n$ is the expanded form of the sum, and we write $\sum\limits_{k = m}^{n} a_k = a_m + a_{m+1} + a_{m+2} + \dots + a_n.$ We call the $k$ the index of the summation, $m$ the lower limit of the summation, and $n$ the upper limit of the summation.

**Product Notation:**
The Greek capital letter pi, $\Pi,$ denotes a product.
If $m$ and $n$ are integers and $m \leq n,$ the symbol $\prod\limits_{k = m}^{n}a_k,$ read the product from $k$ equals $m$ to $n$ of $a$-sub-$k,$ is the product of all the terms $a_m,\ a_{m+1},\ a_{m+2},\ \dots ,\ a_n.$ We write $\prod\limits_{k = m}^{n}a_k = a_m \cdot a_{m+1} \cdot a_{m+2}\ \dots\ a_n.$

**Properties of Summations and Products:**
If $a_m,\ a_{m+1},\ a_{m+2},\ \dots$ and $b_m,\ b_{m+1},\ b_{m+2},\ \dots$ are sequences of real numbers and $c$ is any real number, then the following equations hold for any integer $n \geq m$:
1. $\sum\limits_{k = m}^{n}a_k + \sum\limits_{k=m}^{n}b_k = \sum\limits_{k=m}^{n}(a_k + b_k)$
2. $c\ \cdot\ \sum\limits_{k=m}^{n}a_k = \sum\limits_{k=m}^{n}c\ \cdot\ a_k$
3. $\left( \prod\limits_{k=m}^{n}a_k \right) \ \cdot \ \left( \prod\limits_{k=m}^{n}b_k \right) = \prod\limits_{k=m}^{n}(a_k \ \cdot \ b_k).$

**Factorial Notation:**
The product of all consecutive integers up to a given integer is given a special notation - factorial notation.
For each positive integer $n,$ the quantity $n$ factorial denoted $n!,$ is defined to be the product of all the integers from $1$ to $n: n! = n\ \cdot (n-1)\ \dots\ 3\ \cdot 2\ \cdot 1.$
Zero factorial, denoted $0!,$ is defined to be $a: 0! = 1.$

**$n$ choose $r$:**
Let $n$ and $r$ be integers with $0\leq r\leq n.$ The symbol $\binom{n}{r}$ is read "$n$ choose $r$" and represents the number of subsets of size $r$ that can be chosen from a set with $n$ elements. For all integers $n$ and $r$ with $0 \leq r \leq n, \binom{n}{r} = \frac{n!}{r!(n-r)!}$ 

#### 5.2 - Mathematical Induction I: Proving Formulas

> A good proof is one which makes us wiser.
> - I. Manin, *A Course in Mathematical Logic*, 1977

In natural science courses, deduction and induction are presented as alternative modes of thought - deduction being to infer a conclusion from general principles using the laws of logical reasoning, and induction being to enunciate a general principle after observing it to hold in a large number of specific instances. Mathematical induction as a proof technique is not inductive but deductive. Once proved by mathematical induction, a theorem is known just as certainly as if were proved by any other mathematical method. Thus, in mathematics, inductive reasoning is used in the natural sciences sense, but only to make conjectures, not to prove them.

**Principle of Mathematical Induction:**
Let $P(n)$ be a property that is defined for integers $n,$ and let $a$ be a fixed integer. Suppose the following two statements are true:
1. $P(a)$ is true.
2. For every integer $k \geq a,$ if $P(k)$ is true then $P(k+1)$ is true.
Then the statement, for every integer $n \geq a, P(n)$ is true.

**Method of Proof by Mathematical Induction:**
Consider a statement of the form, "For every integer $n \geq a,$ a property $P(n)$ is true." To prove such a statement, perform the following two steps:
1. (basis step): Show that $P(a)$ is true.
2. (inductive step): Show that for every integer $k \geq a,$ if $P(k)$ is true then $P(k+1)$ is true. To perform this step, suppose that $P(k)$ is true, where $k$ is any particular but arbitrarily chosen integer with $k \geq a.$
   \[This supposition is called the inductive hypothesis.\]
   Then show that $P(k+1)$ is true.

**Sum of the First $n$ integers:**
For every integer $n \geq 1 , 1 + 2 + \dots + n = \frac{n(n+1)}{2}$

**Closed Form:**
If a sum with a variable number of terms is shown to equal an expression that does not contain either an ellipsis or a summation symbol, we say that the sum is written in closed form.

**Sum of a Geometric Sequence:**
For any real number $r$ except 1, and any integer $n \geq 0,\ \sum\limits_{i=0}^{n}r^i = \frac{r^{n+1} - 1}{r - 1}$

#### 5.3 - Mathematical Induction II: Applications 

> \[Mathematical induction is\] the standard proof technique in computer science.
> - Anthony Ralston, 1984

#### 5.6 - Defining Sequences Recursively

> So, Nat'ralists observe, a Flea/Hath smaller Fleas that on hom prey,/And these have smaller Fleas to bite 'em,/And so proceed ad infinitum.
> - Jonathan Swift, 1733

**Defining Sequences Recursively:**
A recurrence relation for a sequence $a_0,\ a_1,\ a_2,\ \dots$ is a formula that relates each term $a_k$ to certain of its predecessors $a_{k-1},\ a_{k-2},\ \dots,\ a_{k-i},$ where $i$ is an integer with $k - i \geq 0.$ If $i$ is a fixed integer, the initial conditions for such a recurrence relation specify the values of $a_0,\ a_1,\ 1_2,\ \dots,\ a_{i-1}.$ If $i$ depends on $k,$ the initial conditions specify the values $a_0,\ a_1,\ \dots,\ a_m,$ where $m$ is an integer with $m \geq 0.$

**Recursive Definitions of Sum and Product:**
Given numbers $a_1,\ a_2,\ \dots,\ a_n,$ where $n$ is a positive integer, the summation from $i=1$ to $n$ of the $a_i,$ denoted $\sum_{i=1}^{n} a_i,$ is defined as follows:
$\sum\limits_{i=1}^{1}a_i = a_1$ and $\sum\limits_{i=1}^{n}a_i = \left( \sum\limits_{i=1}^{n-1}a_i \right) + a_n,$ if $n > 1.$
The product from $i = 1$ to $n$ of the $a_i,$ denoted $\prod_{i=1}^{n} a_i,$ is defined by
$\prod\limits_{i=1}^{1} a_i = a_i$ and $\prod\limits_{i=1}^{n} a_i = \left( \prod\limits_{i=1}^{n-1}a_i \right) \cdot a_n,$ if $n > 1.$

#### 5.9 - General Recursive Definitions and Structural Induction

> GENIE: Oh, aren't you acquainted with recursive acronyms? I thought everybody knew about them. You see, "GOD" stands for "GOD Over Djinn" - which can be expanded as "GOD Over Djinn, Over Djinn" - and that can, in turn, be expanded to "GOD Over Djinn, Over Djinn, Over Djinn" - which can, in its turn, be further expanded.... You can go as far as you like.
> ACHILLES: But I'll never finish!
> GENIE: Of course not. You can never totally expand GOD.
> - Douglas Hofstadter, *Gödel, Escher, Bach*, 1979

**Recursive Definition for the Set of All Strings over a Finite Set:**
Let $A$ be any finite set. Call the elements of $A$ characters, and define the set $S$ of all strings over $A$ as follows:
I.
	Base: $\lambda$ is a string in $S,$ where $\lambda$ denotes the null string, the "string" with no characters.
II.
	Recursion: New strings are formed according to the following rules:
	II(a)
	   If $u$ is any string in $S$ and if $c$ is any character in $A,$ then $uc$ is a string in $S,$ where $uc$ is called the concatenation of $u$ and $c,$ and is obtained by appending $c$ on the right of $u.$
	II(b) 
	   If $u$ is any string in $S,$ then both the concatenation of $\lambda$ and $u,$ denoted $\lambda u,$ and the concatenation of $u$ and $\lambda ,$ denoted $u \lambda ,$ are defined to equal $u$.
	   Symbolically: $\lambda u = u \lambda = u.$
	II(c)
		If $u$ and $v$ are any strings in $S,$ and if $c$ is any character in $A,$ then the concatenation of $u$ and $vc$ is defined to equal the concatenation of $uv$ and $c.$
		Symbolically: $u(vc) = (uv)c.$
III.
	Restriction: Nothing is a string in $S$ other than objects obtained from the base and the recursion.

**Structural Induction for a Recursively Defined Set:**
Let $S$ be a set that has been defined recursively, and let $P(x)$ be a property that objects in $S$ may or may not satisfy. To prove that every object in $S$ satisfies $P(x),$ perform the following two steps:
1. (basis step): Show that $P(a)$ is true for each object $a$ in the base for $S.$
2. (inductive step): Show that for each $x$ in $S,$ if $P(x)$ is true and if $y$ is obtained from $x$ by applying a rule from the recursion, then $P(y)$ is true. To perform this step, suppose that $x$ is an arbitrarily chosen element of $S$ for which $P(x)$ is true. \[This supposition is the inductive hypothesis.\]
   Then show that if $y$ is obtained from $x$ by applying a rule from the recursion for $S,$ then $P(y)$ is true.
Conclusion: Because no objects other than those obtained from the base and recursion are contained in $S,$ steps 1 and 2 prove that $P(x)$ is true for every object $x$ in $S.$

**Length of a String:**
Given the set of all strings $S$ over a finite set $A,$ the length of $ua$ is one more that the length of $u.$
Symbolically: $L(ua) = L(u) + 1$ where $u \in S$ and $a \in A.$


- - -

### Chapter 6 - Set Theory:

#### 6.1 - Set Theory - Definitions and the Element Method of Proof

> The introduction of suitable abstractions is our mental aid to organize and master complexity.
> - E. W. Dijkstra (1930-2002)

**Subsets:**
$A \subseteq B \Leftrightarrow \forall x$, if $x \in A$ then $x \in B$.
$A \not\subseteq B \Leftrightarrow \exists x$, such that $x \in A$ and $x \not\in B$.

**Proper Subsets:**
$A \subset B \Leftrightarrow A \subseteq B$, and there is at least one element in $B$ that is not in $A$.

**Set Equality:**
Given sets $A$ and $B$, $A$ equals $B$, written $A = B$, if, and only if, every element of $A$ is in $B$ and every element of $B$ is in $A$.
Symbolically: $A = B \Leftrightarrow A \subseteq B$ and $B \subseteq A$.

**Universal Set:**
Most mathematical discussions are carried on within some context. For example, in a certain situation all sets being considered might be sets of real numbers. In such a situation, the set of real numbers would be called a universal set or a universe of discourse for the discussion. The universal set is usually denoted by the letter U.

**Operations on Sets:**
![[screenshot_2025-09-12-233105.png]]
Let $A$ and $B$ be subsets of a universal set $U$.
1. The union of $A$ and $B$, denoted $A \cup B$, is the set of all elements that are in at least one of $A$ or $B$.
   Symbolically: $A \cup B = \{x \in U\ |\ x \in A$ or $x \in B\}$
2. The intersection of $A$ and $B$, denoted $A \cap B$, is the set of all elements that are common to both $A$ and $B$.
   Symbolically: $A \cap B = \{x \in U\ |\ x \in A$ and $x \in B\}$
3. The difference of $B$ minus $A$ (or relative complement of $A$ in $B$), denoted $B - A$ or $B \setminus A$, is the set of all elements that are in $B$ and not $A$.
   Symbolically: $B - A = \{x \in U\ |\ x \in B$ and $x \not\in A\}$
4. The complement of $A$, denoted $A^c$, is the set of all elements in $U$ that are not in $A$.
   Symbolically: $A^c = \{ x \in U\ |\ x \not\in A \}$

**Interval Notation:**
Given real numbers $a$ and $b$ with $a \le b$:
$$\begin{align*}
&(\ a, b\ ) = { x \in \mathbb{R}\ |\ a < x < b}&&[\ a, b\ ] = { x \in \mathbb{R}\ |\ a \le x \le b}\\
&(\ a, b\ ] = { x \in \mathbb{R}\ |\ a < x \le b}&&[\ a, b\ ) = { x \in \mathbb{R}\ |\ a \le x < b}
\end{align*}$$
The symbols $\infty$ and $-\infty$ are used to indicate intervals that are unbounded either on the right or on the left:
$$\begin{align*}
(\ a, \infty\ ) &= { x \in \mathbb{R}\ |\ x > a} &&[\ a, \infty\ ] = { x \in \mathbb{R}\ |\ x \ge b}\\
(-\infty, b\ ] &= { x \in \mathbb{R}\ |\ x < b} &&[-\infty, b\ ) = { x \in \mathbb{R}\ |\ x \le b}
\end{align*}$$

**Disjoint Sets:**
Two sets are called disjoint if, and only if, they have no elements in common.
Symbolically: $A$ and $B$ are disjoint $\Leftrightarrow A \cap B = \emptyset$.

**Mutually Disjoint:**
Sets $A_1, A_2, A_3, \dots$ are mutually disjoint (or pairwise disjoint or nonoverlapping) if, and only if, no two sets $A_i$ and $A_j$ with distinct subscripts have any elements in common. More precisely, for all integers $i$ and $j = 1,2,3,\dots$ $A_i \cap A_j = \emptyset$ whenever $i \not = j$.

**Partitions of Sets:**
![[screenshot_2025-09-12-235835.png|200]]
A finite or infinite collection of nonempty sets $\{A_1, A_2, A_3,\dots\}$ is a partition of a set $A$ if, and only if, $A$ is the union of all the $A_i$; the sets $A_1, A_2, A_3,\dots$ are mutually disjoint.

**Power Sets:**
Given a set $A$, the power set of $A$, denoted $\mathcal{P}(A)$, is the set of all subsets of $A$.


#### 6.2 - Properties of Sets

> ... only the last line is a genuine theorem here - everything else is in the fantasy.
> - Douglas Hofstadter, *Gödel, Escher, Bach*, 1979

**Some Subset Relations:**
1. Inclusion of Intersection:
   For all sets $A$ and $B$,
   $(a)\ \ A \cap B \subseteq A$ and $(b)\ \ A \cap B \subseteq B$.
2. Inclusion in Union:
   For all sets $A$ and $B$,
   $(a)\ \ A \subseteq A \cup B$ and $(b)\ \ B \subseteq A \cup B$.
3. Transitive Property of Subsets:
   For all sets $A$, $B$, and $C$,
   if $A \subseteq B$ and $B \subseteq C$, then $A \subseteq C$.

**Set Identities:**
An identity is an equation that is universally true for all elements in some set. Let all sets referred to below be subsets of a universal set $U$.
1. Commutative Laws: For all sets $A$ and $B$,
   $(a)\ \ A \cup B = B \cup A \ \ \text{and} \ \ (b)\ \ A \cap B = B \cap A$.
2. Associative Laws: For all sets $A$, $B$ and $C$,
   $(a)\ \ (A \cup B) \cup C = A \cup (B \cup C) \ \ \text{and} \ \ (b)\ \ (A \cap B) \cap C = A \cap (B \cap C)$.
3. Distributive Laws: For all sets $A$, $B$ and $C$,
   $(a)\ \ A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \ \ \text{and} \ \ (b)\ \ A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.
4. Identity Laws: For every set $A$,
   $(a)\ \ A \cup \emptyset = A \ \ \text{and} \ \ (b)\ \ A \cap U = A$.
5. Complement Laws: For every set $A$,
   $(a)\ \ A \cup A^C = U \ \ \text{and} \ \ (b)\ \ A \cap A^C = \emptyset$.
6. Double Complement Laws: For every set $A$,
   $(A^C)^C = A$
7. Idempotent Laws: For every set $A$,
   $(a)\ \ A \cup A = A \ \ \text{and} \ \ (b)\ \ A \cap A = A$.
8. Universal Bound Laws: For every set A,
   $(a)\ \ A \cup U = U \ \ \text{and} \ \ (b)\ \ A \cap \emptyset = \emptyset$.
9. De Morgan's Laws: For all sets $A$ and $B$,
   $(a)\ \ (A \cup B)^C = A^C \cap B^C \ \ \text{and} \ \ (b)\ \ (A \cap B)^C = A^C \cup B^C$.
10. Absorption Laws: For all sets $A$ and $B$,
    $(a)\ \ A \cup (A \cap B) = A \ \ \text{and} \ \ (b)\ \ A \cap (A \cup B) = A$.
11. Complements of $U$ and $\emptyset$:
    $(a)\ \ U^C = \emptyset \ \ \text{and} \ \ (b)\ \ \emptyset^C = U$.
12. Set Difference Law: For all sets $A$ and $B$,
    $A - B = A \cap B^C$.

**Basic Method for Proving That Sets Are Equal:**
Let sets $X$ and $Y$ be given. To prove that $X = Y$:
1. Prove that $X \subseteq Y$.
2. Prove that $Y \subseteq X$.

**Element Method for Proving a Set Equals the Empty Set:**
To prove that a set $A$ is equal to the empty set $\emptyset$, prove that $X$ has no elements. To do this, suppose $A$ has an element and derive a contradiction
Example:
	Let $A$ be a set, and define $A =\{\ \}$. Suppose that there is at least one element, say $x$, such that $x \in A$. But this is impossible since $A$ has no elements. By Theorem 6.2.4, $A \subseteq \emptyset$ since $A$ has no elements. Also $\emptyset \subseteq A$ since $\emptyset$ has no elements. Thus $A = \emptyset$ by the definition of set equality.


#### 6.3 - Disproofs and Algebraic Proofs

> If a fact goes against common sense, and we are nevertheless compelled to accept and deal with this fact, we learn to alter our notion of common sense.
> - Phillip J. Davis and Reuben Hersh, *The Mathematical Experience*, 1981


- - -

### Chapter 7 - Properties of Functions:

Examples of functions: 
- Sequences - Which are functions defined on sets of integers
- mod and div - Which are functions defined on Cartesian products of integers
- Floor and ceiling - Which are functions from $\mathbb{R}$ to $\mathbb{Z}$
- Truth tables - Which can be regarded as Boolean functions

#### 7.1 - Functions Defined on General Sets

> The theory that has had the greatest development in recent times is without any doubt the theory of functions
> - Vito Volterra, 1888


**The Definition of a Function:**
A function $f$ from a set $X$ to a set $Y$, denoted $f: X \rightarrow Y$, is a relation from $X,$ the domain of $f,$ to $Y,$ the co-domain of $f,$ that satisfies two properties: (1) every element in $X$ is related to some element in $Y,$ and (2) no element in $X$ is related to more than one element in $Y.$ Thus, given any element $x$ in $X,$ there is a unique element in $Y$ that is related to $x$ by $f.$ If we call this element $y,$ then we say that "$f$ sends $x$ to $y$" or "$f$ maps $x$ to $y$" and write $x \xrightarrow{f} y$ or $f: x \rightarrow y.$ The unique element to which $f$ sends $x$ is denoted $f(x)$ and is called $f$ of $x,$ or the output of $f$ for the input $x$, or the value of $f$ at $x,$ or the image of $x$ under $f.$
The set of all values of $f$ taken together is called the range of $f$ or the image of $X$ under $f.$
Symbolically:
	Range of $f =$ image of $X$ under $f = \{y \in Y \mid y = f(x),$ for some $x$ in $X\}.$
Given an element $y$ in $Y,$ there may exist elements in $X$ with $y$ as their image. When $x$ is an element such that $f(x) = y,$ then $x$ is called a preimage of $y$ or an inverse image of $y.$ The set of all inverse images of $y$ is called the inverse image of $y.$
Symbolically:
	The inverse image of $y = \{ x \in X \mid f(x) = y\}.$

**Function Equality:**
If $F: X \rightarrow Y$ and $G : X \rightarrow Y$ are functions, then $F = G$ if, and only if, $F(x) = G(x)$ for every $x \in X.$

**Identity Function on a Set:**
Given a set $X,$ define a function $I_X$ from $X$ to $X$ by $I_X(x) = x$ for each $x$ in $X.$
The function $I_X$ is called the identity function on $X$ because it sends each element of $X$ to the element that is identical to it.

**Logarithms and Logarithmic Functions:**
Let $b$ be a positive real number with $b \neq 1.$ For each positive real number $x,$ the logarithm with bas $b$ of $x,$ written $\log_b\ x,$ is the exponent to which $b$ must be raised to obtain $x.$
Symbolically: $\log_b\ x = y \ \ \Leftrightarrow \ \ b^y = x.$
The logarithm function with base $b$ is the function from $\mathbb{R}^+$ to $\mathbb{R}$ that takes each positive real number $x$ to $\log_b\ x.$

**Boolean Functions:**
An ($n$-place) Boolean function $f$ is a function whose domain is the set of all ordered $n$-tuples of 0's and 1's and whose co-domain is the set $\{0, 1\}.$ More formally, the domain of a Boolean function can be described as the Cartesian product of $n$ copies of the set $\{0, 1\},$ which is denoted $\{0, 1\}^n.$ Thus $f: \{0, 1\}^n \rightarrow \{0, 1\}.$

**"Functions" That Are Not Well-Defined:**
In general, we say that a "function" is not well defined if it fails to satisfy at least one of the requirements for being a function.

**Image and Reverse Image:**
If $f: X \rightarrow Y$ is a function and $A \subseteq X$ and $C \subseteq Y,$ then $f(A) = \{y \in Y \mid y = f(x)$$ for some $x$ in $A\}$ and $f^{-1}(C) = \{ x \in X \mid f(x) \in C\}.$
$f(A)$ is called the image of $A,$ and $f^{-1}(C)$ is called the inverse image of $C.$


#### 7.2 - One-to-One, Onto, and Inverse Functions

> Don't accept a statement just because it is printed.
> - Anna Pell Wheeler (1883 - 1966)

Functions that satisfy both properties of being one-to-one and onto are called one-to-one correspondences or one-to-one onto functions. When a functions is a one-to-one correspondence, the elements of its domain and co-domain match up perfectly, and we can define an inverse function for the co-domain to the domain that "undoes" the action of the function.

**One-to-one Functions:**
Let $F$ be a function from a set $X$ to a set $Y.$ $F$ is one-to-one (or injective) if, and only if, for all elements $x_1$ and $x_2$ in $X,$ if $F(x_1) = F(x_2),$ then $x_1 = x_2,$ or equivalently, if $x_1 \neq x_2,$ then $F(x_1) \neq F(x_2).$
Symbolically:
$F: X \rightarrow Y$ is one-to-one $\Leftrightarrow \forall x_1, x_2 \in X,$ if $F(x_1) = F(x_2)$ then $x_1 = x_2.$

**Hash Functions:**
A hash function is an example of a one-to-one function. A hash function is a function defined from a larger, possibly infinite, set of data to a smaller fixed-size set of integers. Most hash functions are modifications of mod functions and are defined using prime numbers to increase the change that their values will be scattered rather than clustered together. In addition, making their co-domains $50\%$ or $100\%$ larger than their domains makes it more likely that they will be one-to-one. Nonetheless, two input values may collide, that is , have the same output value, and various methods are used to avoid such a collision. One of the simplest collision resolution methods is called a linear probe. A special class of hash functions, known as cryptographic hash functions, is used to secure digital data. A cryptographic has function is designed to satisfy the following conditions:
1. It is a function from bit strings to bit strings of a fixed length
2. It is close to being one-to-one: the probability of collisions is very small.
3. It is close to being a one-way function: given any bit string in its range, finding the inverse image of the string is computationally very difficult.
4. Its values can be quickly computed
5. A very slight change in an input string results in an extensive change in the output string

**Modulo Formula:**
$n \text{ mod } m = n - (n \text{ div } m)$
In other words, divide $n$ by $m,$ multiply the integer part of the result by $m.$

**Onto functions:**
When a function is onto, its range is equal to its co-domain.
Let $F$ be a function from a set $X$ to a set $Y.$ $F$ is onto (or surjective) if, and only if, given any element $y$ in $Y,$ it is possible to find an element $x$ in $X$ with the property that $y = F(x).$
Symbolically:
$F: X \rightarrow Y$ is onto $\Leftrightarrow$ $\forall y \in Y, \exists x \in X, \text{ such that } \forall x \in X, f(x) = y.$

**One-to-One Correspondences:**
A one-to-one correspondence (or bijection) from a set $X$ to a set $Y$ is a function $F: X \rightarrow Y$ that is both one-to-one and onto.

**Inverse Functions:**
If $F$ is a one-to-one correspondence from a set $X$ to a set $Y,$ then there is a function from $Y$ to $X$ that "undoes" the action of $F;$ that is, it sends each element of $Y$ back to the element of $X$ that it came from. This function is called the inverse function of $F.$
Suppose $F: X \rightarrow Y$ is a one-to-one correspondence; in other words suppose $F$ is one-to-one and onto. Then there is a function $F^{-1} : Y \rightarrow X$ that is defined as follows: Given any element $y$ in $Y, F^{-1}(y) =$ that unique element $x$ in $X$ such that $F(x)$ equals $y.$ Or equivalently, $F^{-1} = x \ \ \Leftrightarrow \ \ y = F(x).$

#### 7.3 - Composition of Functions

> It is no paradox to say that in our most theoretical moods we may be nearest to our most practical applications.
> - Alfred North Whitehead

**Composition of Functions:**
Combining two functions by chaining the output from one to the input of another is called composing them. The resulting functions is called the composition of the two functions.
Let $f: X \rightarrow Y$ and $g: Y' \rightarrow Z$ be functions with the property that the range of $f$ is a subset of the domain of $g.$ Define a new function $g \circ f: X \leftarrow Z$ as follows: $(g \circ f)(x) = g(f(x)$ for each $x \in X,$ where $g \circ f$ is read "$g$ circle $f$" and $g(f(x)$ is read "$g$ of $f$ of $x.$" The function $g \circ f$ is called the composition of $f$ and $g.$

**Composition of One-to-One Function:**
If $f: X \rightarrow Y$ and $g: Y \rightarrow Z$ are both one-to-one functions, then $g \circ f$ is one-to-one.

**Composition of Onto Functions:**
If $f: X \rightarrow Y$ and $g: Y \rightarrow Z$ are both onto functions, then $g \circ f$ is onto.


- - -

### Chapter 8 - Properties of Relations:

#### 8.1 - Relations on Sets

> Strange as it may sound, the power of mathematics rests on its evasion of all unnecessary thought and on its wonderful saving of mental operations.
> - Ernst Mach (1838-1916)

A more formal way to refer to the kind of relation defined in Section 1.3 is to call it a binary relation because it is a subset of a Cartesian product of two sets. An $n$-ary relation is defined to be a subset of a Cartesian product of $n$ sets, where $n$ is any integer greater than or equal to two. Such a relation is the fundamental structure used in relational databases.

**The Less-than Relation for Real Numbers:**
	Define a relation $L$ from $\mathbb{R}$ to $\mathbb{R}$ as follows:
	For all real numbers $x$ and $y$,
	$x\ L\ y \Leftrightarrow x < y$

**The Congruence Modulo 2 Relation:**
	Define a relation $E$ from $\mathbb{Z}$ to $\mathbb{Z}$ as follows:
	For every $(m, n) \in \mathbb{Z} \times \mathbb{Z}$,
	$m\ E\ n \Leftrightarrow m - n\ \text{is even.}$

**The Inverse of a Relation:**
Let $R$ be a relation from $A$ to $B$. Define the inverse relation $R^{-1}$ from $A$ to $B$ as follows: $R^{-1} = \{(y,x) \in B \times A\ |\ (x,y) \in R\}$.
Operationally: For all $x \in A$ and $y \in B$, $(y, x) \in R^{-1} \Leftrightarrow (x,y) \in R$.

**Directed Graph of a Relation:**
A relation on a set $A$ is a relation from $A$ to $A$. When a relation $R$ is defined on a set $A$, the arrow diagram of the relation can be modified so that it becomes a directed graph. Instead of representing $A$ as two separate sets of points, represent $A$ only once, and draw and arrow from each point of $A$ to each related point. If a point is related to itself, a loop is drawn that extends out from the point and goes back to it. For all points $x$ and $y$ in $A$, there is an arrow from $x$ to $y \Leftrightarrow x\ R\ y \Leftrightarrow (x, y) \in R$.
Example:
	Let $A = \{ 3, 4, 5, 6, 7, 8 \}$ and define a relation $R$ on $A$ as follows:
	For every $x, y \in A$, $x\ R\ y \Leftrightarrow 2\ \ (x,- y)$
	![[screenshot_2025-09-13-163440.png|200]]

**N-ary Relations:**
Given sets $A_1 , A_2, \dots, A_n$ an $n$-ary relation $R$ on $A_1 \times A_2 \times \dots \times A_n$ is a subset of $A_1 \times A_2 \times \dots \times A_n$. The special cases of 2-ary, 3-ary, and 4-ary relations are called binary, ternary, and quaternary relations, respectively.


#### 8.2 - Reflexivity, Symmetry, and Transitivity

> Mathematics is the tool specially suited for dealing with abstract concepts of any kind and there is no limit to its power in this field.
> - P. A. M. Dirac (1902-1984)

**Reflexive, Symmetric, and Transitive Properties of Relations:**
Let $R$ be a relation of a set $A$
1. $R$ is reflexive if, and only if, for every $x \in A, x\ R\ x$.
	Or written as:
		For every $x$ in $A, (x, x) \in R$.
	In informal terms:
		Each element is related to itself.
	On a directed graph:
		Each point of the graph has an arrow looping around from it and going back to it.
2. $R$ is symmetric if, and only if, for every $x, y \in A$, if $x\ R\ y$ then $y\ R\ x$.
	Or written as:
		For every $x$ and $y$ in $A$, if $(x, y) \in R$ then $(y, x) \in R$.
	In informal terms:
		If any one element is related to any other element, then the second element is related to the first.
	On a directed graph:
		In each case where there is an arrow going from one point to a second, there is an arrow going from the second point back to the first.
3. $R$ is transitive if, and only if, for every $x, y, z \in A$, if $x\ R\ y$ and $y\ R\ z$ then $x\ R\ z$.
	Or written as:
		For every $x$, $y$, and $z$ in $A$, if $(x, y) \in R$ and $(y, z) \in R$ then $(x, z) \in R$.
	In informal terms:
		If any one element is related to a second and that second element is related to a third, then the first element is related to the third.
	On a directed graph:
		In each case where there is an arrow going from one point to a second and from the second point to a third, there is an arrow going from the first point to the third. That is, there ar no "incomplete directed triangles" in the graph.
Example of a reflexive, symmetric and transitive relation:
	Let $A = \{2,3,4,6,7,9\}$ and define a relation $R$ on $A$ as follows:
	For every $x, y \in A,\ \ x\ R\ y \ \ \Leftrightarrow \ \ 3\ |\ (x - y)$
	![[screenshot_2025-09-13-170111.png|300]]


#### 8.3 - Equivalence Relations

**Relation Induced by the Partition:**
A partition of a set $A$ is a finite or infinite collection of nonempty, mutually disjoint subsets whose union is $A$. Given a partition of a set $A$, the relation induced by the partition, $R$, is defined on $A$ as follows: For every $x, y \in A, \ \ x\ R\ y \ \ \Leftrightarrow$ there is a subset $A_i$ of the partition such that both $x$ and $y$ are in $A_i$. Relation induced by a partition of a set satisfies all three properties of reflexivity, symmetry, and transitivity.
Example:
	Let $A = \{ 0, 1, 2, 3\}$ and consider the following partition of $A: \{0, 3\}, \{1\}, \{2\}.$
	$R = \{(0,0), (0,3), (3,0), (3,3), (1,1), (2,2)\}$

**Equivalence Relation:**
A relation on a set that satisfies the three properties of reflexivity, symmetry, and transitivity is called an equivalence relation.

**Equivalent Classes of an Equivalence Relation:**
Suppose $A$ is a set and $R$ is an equivalence relation on $A$. For each element $a$ in $A$, the equivalence class of $a$, denoted $[a]$ and called the class of $a$ for short, is the set of all elements $x$ in $A$ such that $x$ is related to $a$ by $R$.
Symbolically: $[a] = \{ x \in A\ |\ x\ R\ a \}$

**Representative:**
Suppose $R$ is an equivalence relation on a set $A$ and $S$ is an equivalence class of $R$. A representative of the class $S$ is any element $a$ such that $[\ a\ ] = S.$

**Modulo:**
Let $m$ and $n$ be integers and let $d$ be a positive integer. We say that $m$ is congruent to $n$ modulo $d$ and write $m \equiv n \pmod d$ if, and only if, $d\;|\;(m - n).$
Symbolically: $m \equiv n \pmod d \ \ \Leftrightarrow \ \ d\ |\ (m - n).$


#### 8.5 - Partial Order Relations

> There is no branch of mathematics, however abstract, which may not some day be applied to phenomena of the real world.
> - Nicolai Ivanovitch Lobachevsky (1792 - 1856)

**Antisymmetry:**
Let $R$ be a relation on a set $A$. $R$ is antisymmetric if, and only if, for every $a$ and $b$ in $A$, if $a\ R\ b$ and $b\ R\ a$ then $a = b.$
On a directed graph:
	Saying that a relation is antisymmetric is the same as saying that whenever there is an arrow going from one element to another distinct element, there is not an arrow going back from the second to the first.

**Partial Order Relations:**
Let $R$ be a relation defined on a set $A$. $R$ is a partial order relation if, and only if, $R$ is reflexive, antisymmetric, and transitive.
An example of a partial order relation is the "divides" relation on a set of positive integers:
	Let $|$ be the "divides" relation on a set $A$ of positive integers. That is, for all $a$ and $b$ in $A$, $a \mid b \ \ \Leftrightarrow \ \ ka$ for some integer $k$.
A fundamental partial order relation is the "subset" relation on a set of sets:
	 Let $\mathcal{A}$ be any collection of sets and define the "subset" relation, $\subseteq$, on $\mathcal{A}$ as follows: For every $U, V \in \mathcal{A}, \ \ U \subseteq V \ \ \Leftrightarrow$ for each $x,$ if $x$ in $V.$
Another fundamental partial order relation is the "less than or equal to" relation on a set of real numbers:
	Let $S$ be a set of real numbers and define the "less than or equal to" relation , $\le$, on $S$ as follows: For all real numbers $x$ and $y$ in $S, x \le y \Leftrightarrow x \lt y$ or $x = y.$
Because of the special paradigmatic role played by the $\le$ relation in the study of partial order relations, the symbol $\preceq$ is often used to refer to a general partial order relation, and the notation $x \preceq y$ is read "$x$ is less than or equal to $y$" or "$y$ is greater than or equal to $x$."

**Lexicographic Order:**
Let $A$ be a set with a partial order relation $R$, and let $S$ be a set of strings over $A$. Define a relation $\preceq$ on $S$ as follows:
Let $s$ and $t$ be any strings in $S$ of lengths $m$ and $n$, respectively, where $m$ and $n$ are positive integers, and let $s_m$ and $t_m$ be the characters in the $m$th position for $s$ and $t$, respectively.
1. If $m \le n$ and the first $m$ characters of $s$ and $t$ are the same, then $s \preceq t$.
2. If the first $m - 1$ characters in $s$ and $t$ are the same, $s_m\ R\ t_m$, and $s_m \neq t_m,$ then $s \preceq t.$
3. If $\lambda$ is the null string then $\lambda \preceq s.$
If no strings are related by $\preceq$ other than by these three conditions, then $\preceq$ is a partial order relation on $S.$

**Hasse Diagram:**
For a partial order relation defined on a finite set, a Hasse diagram can be drawn rather than a directed graph. It is somewhat simpler and more readable.
To obtain a Hasse diagram, proceed as follows: Start with a directed graph of the relation, placing vertices on the page so that all arrows point upward. Then eliminate:
1. The loops at all the vertices.
2. All the arrows whose existence is implied by the transitive property.
3. The direction indicators on the arrows.
Example:
	Let $A = \{1, 2, 39, 18\}$ and consider the "divides" relation on $A$: For every $a, b, \in A,\ \ a \mid b \ \ \Leftrightarrow \ \ b = ka$ for some integer $k.$
	![[screenshot_2025-09-14-171713.png]]

**Comparable and Noncomparable elements:**
Suppose $\preceq$ is a partial relation on a set $A$. Elements $a$ and $b$ of $A$ are said to be comparable if, and only if, either  $a \preceq b$ or $b \preceq a$. Otherwise, $a$ and $b$ are called noncomparable.

**Total Order Relations:**
When all the elements of a partial order relation are comparable, the relation is called a total order. If $R$ is a partial order relation on a set $A$, and for any two elements $a$ and $b$ in $A$ either $a\ R\ b$ or $b\ R\ a$, then $R$ is a total order relation on $A.$ A Hasse diagram for a total order relation can be drawn as a single vertical chain. Examples of total order relations: The "less than or equal to" relation on sets of real numbers, and the lexicographic order of a set of words in a dictionary.

**Chains:**
A set that is partially ordered but not totally ordered may have totally ordered subsets. Such subsets are called chains.
Let $A$ be a set that is partially ordered with respect to a relation $\preceq$. A subset $B$ of $A$ is called a chain if, and only if, the elements in each pair of elements in $B$ are comparable. In other words, $a \preceq b$ or $b \preceq a$ for every $a$ and $b$ in $B$. the length of a chain is one less that the number of elements in the chain.

**The Maximal Element in Partially Ordered Sets:**
A maximal element in a partially ordered set is an element that is greater than or equal to every element to which it is comparable. A greatest element in a partially ordered set is an element that is greater than or equal to every element in the set. Minimal and least elements are defined similarly.
Let a set $A$ be partially ordered with respect to a relation $\preceq$.
1. An element $a$ in $A$ is called a maximal element of $A$ if, and only if, for each $b$ in $A$, either $b \preceq a$ or $b$ and $a$ are not comparable.
2. An element $a$ in $A$ is called a greatest element of $A$ if, and only if, for each $b$ in $A, b \preceq a.$
3. An element $a$ in $A$ is called a minimal element of $A$ if, and only if, for each $b$ in $A$, either $a \preceq b$ or $b$ and $a$ are not comparable.
4. An element $a$ in $A$ is called a least element of $A$ if, and only if, for each $b$ in $A, a \preceq b.$

**Compatible Partial Order Relations:**
Given partial order relations $\preceq$ and $\preceq '$ on a set $A$, $\preceq '$ is compatible with $\preceq$ if, and only if, for every $a$ and $b$ in $A$, if $a \preceq b$ then $a \preceq ' b$.

**Topological Sorting:**
Given partial order relations $\preceq$ and $\preceq '$ on a set $A$, $\preceq '$ is a topological sorting for $\preceq$ if, and only if, $\preceq '$ is a total order that is compatible with $\preceq.$


- - -

### Chapter 10 - Theory of Graphs and Trees:

#### 10.1 - Trails, Paths, and Circuits

> One can begin to reason only when a clear picture has been formed in the imagination.
> - W. W. Sawyer, *Mathematician's Delight*, 1943

**Travel in a Graph:**
![[screenshot_2025-10-02-103954.png]]
Let $G$ be a graph, and let $v$ and $w$ be vertices in $G.$ A walk from $v$ to $w$ is a finite alternating sequence of adjacent vertices and edges of $G.$ Thus a walk has the form $v_0 e_1 v_1 e_2 \dots v_{n-1} e_n v_n,$ where the $v$'s represent vertices, the $e$'s represent edges, $v_0 = v, v_n = w,$ and for each $i = 1, 2, \dots, n, v_{i-1}$ and $v_i$ are the endpoints of $e_i.$ The trivial walk from $v$ to $v$ consists of the single vertex $v.$
A trail from $v$ to $w$ is a walk from $v$ to $w$ that does not contain a repeated edge.
A path from $v$ to $w$ is a trail that does not contain a repeated vertex.
A closed walk is a walk that starts and ends at the same vertex.
A circuit is a closed walk that contains at least one edge and does not contain a repeated edge.
A simple circuit is a circuit that does not have any other repeated vertex except the first and last.

**Subgraphs:**
A graph $H$ is said to be a subgraph of a graph $G$ if, and only if, every vertex in $H$ is also a vertex in $G,$ every edge in $H$ is also an edge in $G,$ and every edge in $H$ has the same endpoints as it has in $G.$

**Connectedness:**
Roughly speaking, a graph is connected if it is possible to travel from any vertex to any other vertex along a sequence of adjacent edges of the graph. The formal definition of connectedness is stated in terms of walks.
Let $G$ be a graph. Two vertices $v$ and $w$ of $G$ are connected if, and only if, there is a walk from $v$ to $w.$ The graph $G$ is connected if, and only if, given any two vertices $v$ and $w$ in $G,$ there is a walk from $v$ to $w.$
Symbolically:
	$G$ is connected  $\Leftrightarrow$  $\forall$ vertices $v$ and $w$ in $G,\ \exists$ a walk from $v$ to $w.$

**Connected Components:**
A graph $H$ is a connected component of a graph $G$ if, and only if,
1. $H$ is subgraph of $G;$
2. $H$ is connected; and
3. no connected subgraph of $G$ has $H$ as a subgraph and contains vertices or edges that are not in $H.$

**Euler Circuits:**
Let $G$ be a graph. An Euler circuit for $G$ is a circuit that contains every vertex and every edge of $G.$ That is, an Euler circuit for $G$ is a sequence of adjacent vertices and edges in $G$ that has at least one edge, starts and ends at the same vertex, uses every vertex of $G$ at least once, and uses every edge of $G$ exactly once.
A graph $G$ has an Euler circuit if, and only if, $G$ is connected and every vertex of $G$ has positive even degree.

**Euler Trails:**
Let $G$ be a graph, and let $v$ and $w$ be two distinct vertices of $G.$ An Euler trail from $v$ to $w$ is a sequence of adjacent edges and vertices that starts at $v,$ ends at $w,$ passes through every vertex of $G$ at least once, and traverses every edge of $G$ exactly once.
There is an Euler trail from $v$ to $w$ if, and only if, $G$ is connected, $v$ and $w$ have odd degree, and all other vertices of $G$ have positive even degree.

**Hamiltonian Circuit:**
Given a graph $G,$ a Hamiltonian circuit for $G$ is a simple circuit that includes every vertex of $G.$ That is, a Hamiltonian circuit for $G$ is a sequence of adjacent vertices and distinct edges in which every vertex of $G$ appears exactly once, except for the first and the last, which are the same.
If a graph $G$ has a Hamiltonian circuit, then $G$ has a subgraph $H$ with the following properties:
1. $H$ contains every vertex of $G.$
2. $H$ is connected.
3. $H$ has the same number of edges as vertices.
4. Every vertex of $H$ has degree 2.


#### 10.2 - Matrix Representation of Graphs

> Order and simplification are the first steps toward the mastery of a subject.
> - Thomas Mann, *The Magic Mountain*, 1924

**Matrices:**
![[screenshot_2025-10-02-132455.png|400]]
Matrices are two-dimensional analogues of sequences. They are also called two-dimensional arrays. An $m \times n$ (red "$m$ by $n$") matrix $A$ over a set $S$ is a rectangular array of elements of $S$ arranged into $m$ rows and $n$ columns. We write $A = (a_{ij}).$ The entry $a_{ij}$ in the $i$th row and $j$th column of $A$ is called the $ij$th entry of $A.$ An $m \times n$ matrix is said to have size $m \times n.$ If $A$ and $B$ are matrices, then $A = B$ if, and only if, $A$ and $B$ have the same size and the corresponding entries of $A$ and $B$ are all equal. A matrix for which the numbers of rows and columns are equal is called a square matrix.
![[screenshot_2025-10-02-131809.png|400]]
If $A$ is a square matrix of size $n \times n,$ then the main diagonal of $A$ consists of all the entries $a_{11},\ a_{22},\ \dots,\ a_{nn}.$

**The Adjacency Matrix of a Directed Graph:**
![[screenshot_2025-10-02-131820.png|400]]
Let $G$ be a directed graph with ordered vertices $v_1,\ v_2,\ \dots,\ v_n.$ The adjacency matrix of $G$ is the $n \times m$ matrix $A = (a_{ij})$ over the set of nonnegative integers such that $a_{ij} =$ the number of arrows from $v_i$ to $v_j$ for all $i, j = 1,\ 2,\ \dots,\ n.$

**The Adjacency Matrix of a Undirected Graph:**
Let $G$ be an undirected graph with ordered vertices $v_1,\ v_2,\ \dots,\ v_n.$ The adjacency matrix of $G$ is the $n \times n$ matrix $A = (a_{ij})$ over the set of nonnegative integers such that $a_{ij} =$ the number of edges connecting $v_i$ and $v_j$ for every $i$ and $j = 1,\ 2,\ \dots,\ n.$

**Symmetric Matrices:**
If the appearance of a matrix remains the same if the entries of the matrix are flipped across its main diagonal the matrix is said to be symmetric. An $n \times n$ square matrix $A = (a_{ij})$ is called symmetric if, and only if, for every $i$ and $j = 1,\ 2,\ \dots,\ n, \ \ a_{ij} = a_{ji}.$

**Matrix Row/Column Dot Product:**
Suppose that all entries in matrices $A$ and $B$ are real numbers. If the number of element, $n,$ in the $i$th row of $A$ equals the number of elements in the $j$th column of $b,$ then the scalar product or dot product of the $i$th row of $A$ and $j$th column of $B$ is the real number obtained as follows:
![[screenshot_2025-10-02-140554.png|400]]

**Matrix Multiplication:**
The product of two matrices is built up of scalar or dot products of their individual rows and columns.
Let $A = (a_{ij})$ be an $m \times k$ matrix and $B = (a_{ji})$ a $k \times n$ matrix with real entries. The (matrix) product of $A$ times $B,$ denoted $AB,$ is that matrix $(c_{ij})$ defined as follows:
![[screenshot_2025-10-02-141138.png]]
where $c_{ij} = a_{i1} \ b_{1j} + a_{i2} \ b_{2j} + \dots + a_{ik} \ b_{kj} = \sum\limits_{r=1}^{k} a_{ir} \ b_{rj},$ for each $i = 1,\ 2,\ \dots,\ m$ and $j = 1,\ 2,\ \dots,\ n.$

**The Identity Matrix:**
For each positive integer $n,$ the $n \times n$ identity matrix, denoted $I_n = (\delta_{ij})$ or just $I$ (if the size of the matrix is obvious from context), is the $n \times n$ matrix in which all the entries in the main diagonal are $1$'s and all other entries are $0$'s. In other words, $\delta_{ij} = \begin{cases}1 & \text{ if } i = j \\0 &\text{ if } i \neq j \end{cases}$ , for every $i, j = 1,\ 2,\ \dots,\ n.$

**Powers of a Matrix:**
For any $n \times n$ matrix $A,$ the powers of $A$ are defined as follows:
$A^0 = I$ where $I$ is the $n \times n$ identity matrix
$A^n = AA^{n-1}$ for every integer $n \geq 1.$


#### 10.3 - Isomorphisms of Graphs

> Thinking is a momentary dismissal of irrelevancies.
> -R. Buckminster Fuller, 1969

**Graph Isomorphism:**
Two graphs that are the same except for the labeling of their vertices and edges are called isomorphic. Let $G$ and $G'$ be graphs with vertex sets $V(G)$ and $V(G')$ and edge sets $E(G)$ and $E(G'),$ respectively. $G$ is isomorphic to $G'$ if, and only if, there exist one-to-one correspondences $g: V(G) \rightarrow V(G')$ and $h: E(G) \rightarrow E(G')$ that preserve the edge-endpoint functions of $G$ and $G'$ in the sense that for each $v \in V(G)$ and $e \in E(G),$ $v$ is an endpoint of $e$  $\Leftrightarrow$  $g(v)$ is an endpoint of $h(e).$ In words, $G$ is isomorphic to $G'$ if, and only if, the vertices and edges of $G$ and $G'$ can be matched up by one-to-one, onto functions in such a way that the edges between corresponding vertices correspond to each other.

**Isomorphic Invariant:**
A property $P$ is called an invariant for graph isomorphism if, and only if, given any graphs $G$ and $G',$ if $G$ has property $P$ and $G'$ is isomorphic to $G,$ then $G'$ has property $P.$

**Graph Isomorphism for Simple Graphs:**
If $G$ and $G'$ are simple graphs, then $G$ is isomorphic to $G'$ if, and only if, there exists a one-to-one correspondence $g$ from the vertex set $V(G)$ of $G$ to the vertex set $V(G')$ of $G'$ that preserves the edge-endpoint functions of $G$ and $G'$ in the sense that for all vertices $u$ and $v$ of $G,$ $\{ u,v \}$ is an edge in $G$  $\Leftrightarrow$  $\{ g(u),g(v) \}$ is an edge in $G'.$


#### 10.4 - Trees: Examples and Basic Properties

> We are not very pleased when we are forced to accept a mathematical truth by virtue of a complicated chain of formal conclusions and computations, which we traverse blindly, link by link, feeling our way by touch. We want first an overview of the aim and of the road; we want to understand the idea of the proof, the deeper context.
> - Hermann Weyl, 1885-1955

**Trees:**
A graph is said to be circuit-free if, and only if, it has no circuits. A graph is called a tree if, and only if, it is circuit-free and connected. A trivial tree is a graph that consists of a single vertex. A graph is called a forest if, and only if, it is circuit free and not connected. For any positive integer $n,$ any tree with $n$ vertices has $n - 1$ edges.

**Leaves:**
Let $T$ be a tree. If $T$ has at least two vertices, then a vertex of degree $1$ in $T$ is called a leaf (or a terminal vertex), and a vertex of degree greater than $1$ in $T$ is called an internal vertex (or a branch vertex). The unique vertex in a trivial tree is also called a leaf or terminal vertex.


#### 10.5 - Rooted Trees

> Let us grant that the pursuit of mathematics is a divine madness of the human spirit, a refuge from the goading urgency of contingent happenings.
> - Alfred North Whitehead, 1861 - 1947

**Rooted Trees:**
![[screenshot_2025-10-02-190133.png|600]]
A rooted tree is a tree in which there is one vertex that is distinguished from the others and is called the root. The level of a vertex is the number of edges along the unique path between it and the root. The height of a rooted tree is the maximum level of any vertex of the tree. Given the root or any internal vertex $v$ of a rooted tree, the children of $v$ are all those vertices that are adjacent to $v$ and are one level farther away from the root than $v.$ If $w$ is a child of $v,$ then $v$ is called the parent of $w,$ and two distinct vertices that are both children of the same parent are called siblings. Given two distinct vertices $v$ and $w,$ if $v$ lies on the unique path between $w$ and the root, then $v$ is an ancestor of $w$ and $w$ is a descendant of $v.$

**Binary Trees:**
![[screenshot_2025-10-02-190143.png|600]]
A binary tree is a rooted tree in which every parent has at most two children. Each child in a binary tree is designated either a left child or a right child (but not both), and every parent has at most one left child and one right child. A full binary tree is a binary tree in which each parent has exactly two children. Given any parent $v$ in a binary tree $T,$ if $v$ has a left child, then the left subtree of $v$ is the binary tree whose root is the left child of $v,$ whose vertices consist of the left child of $v$ and all its descendants, and whose edges consist of all those edges of $T$ that connect the vertices of the left subtree. The right subtree of $v$ is defined analogously.


#### 10.6 - Spanning Trees and a Shortest Path Algorithm

> I contend that each science is a real science insofar as it is mathematics.
> - Immanuel Kant, 1724 - 1804

**Spanning Trees:**
A spanning tree for a graph $G$ is a subgraph of $G$ that contains every vertex of $G$ and is a tree.

**Weighted Graphs:**
A weighted graph is a graph for which each edge has an associated positive real number weight. The sum of the weights of all the edges is the total weight of the graph. A minimum spanning tree for a connected, weighted graph is a spanning tree that has the least possible total weight compared to all other spanning trees for the graph. If $G$ is a weighted graph and $e$ is an edge of $G,$ then $w(e)$ denotes the weight of $e$ and $w(g)$ denotes the total weight of $G.$


## Notater fra "Discrete Math (Full Course)" av Trefor Bazett:
- - - 

Video: [Intro to Sets | Examples, Notation & Properties](https://youtu.be/B1v2-nGXNzs)
Video: [Set-Roster vs Set-Builder notation](https://youtu.be/aTlR03t1dTQ)
Video: [The Empty Set & Vacuous Truth](https://youtu.be/GqvX4Fi0jbM)

**Set-Roster Notation:**
	{0,2,4,5,...}

**Set-Builder Notation:**
	{x | P(x)}

Video: [Cartesian Product of Two Sets A x B](https://youtu.be/ufjEv-5nmcA)

**Cartesian Product of two sets:**
	The Cartesian Product $A \times B$ is the set of all ordered pairs $(a, b)$ where $a \in A$ and $b \in B$

Video: [Relations between two sets | Definition + First Examples](https://youtu.be/0dzNlrNJYdc)

**Relations:**
	A relation R between $A$ and $B$ is a subset of $A \times B$

Video: [The intuitive idea of a function](https://youtu.be/G8qvOZ9DE3c)
Video: [Formal Definition of a Function using the Cartesian Product](https://youtu.be/-a5FaFp87N4)
Video: [Example: Is this relation a function?](https://youtu.be/b_sxTCjruJE)

**Functions:**
	A function $F$ between $A$ and $B$ is a relation between $A$ and $B$ such that:
	1. For every element $x \in A$ there is an element $y \in B$ such that $(x,y) \in F$
	2. If $(x, y) \in F$ and $(x,z) \in F$ then $y = z$

Video: [Intro to Logical Statements](https://youtu.be/q2eyZZK-OIk)
Video: [Intro to Truth Tables | Negation, Conjunction, and Disjunction](https://youtu.be/7mulE-zramc)
Video: [Truth Table Example: ~p V ~q](https://youtu.be/LNSfM86I8is)
Video: [Logical Equivalence of Two Statements](https://youtu.be/U2zPxuj8mnI)

**Logical equivalence of two statements:**
	Two statements are logically equivalent if they have the same truth table

Video: [Tautologies and Contradictions](https://youtu.be/Ji2vr-9duPI)

**Tautologies and contradictions:**
	A tautology $t$ is a statement that is always true
	A contradiction $c$ is a statement that is always false

Video: [3 Ways to Show a Logical Equivalence | Ex: DeMorgan's Laws](https://youtu.be/93CxSLi89Ok)

**DeMorgan's laws:**
	$\sim (p \lor q) \equiv (\sim p) \land (\sim q)$
	$\sim (p \land q) \equiv (\sim p) \lor (\sim q)$

**Double negative law:**
	$\sim (\sim p) \equiv p$

**Identity laws:**
	$p \lor c \equiv p$
	$p \land t \equiv p$

**Universal Bound laws:**
	$p \lor t \equiv t$
	$p \land c \equiv c$

Video: [Vacuously True Statements](https://youtu.be/AQ0f4rsbsrQ)

**Vacuously true statements:**
	When the hypothesis is false, the statement is vacuously true

Video: [Conditional Statements: if p then q](https://youtu.be/F3544ZyO-eU)

**Conditional statements:**
	$p \rightarrow q$ means: "if $p$ is TRUE then $q$ is TRUE
	$p \rightarrow q \equiv \sim p \lor q$

Video: [Negating a Conditional Statement](https://youtu.be/j7qVcc6X8g4)

**Negating a conditional statement:**
	$\sim (p \rightarrow q) \equiv p \land \sim q$

Video: [Contrapositive of a Conditional Statement](https://youtu.be/h83bzYAfgrM

**Contrapositive of a conditional statement:**
	$p \rightarrow q \equiv \sim q \rightarrow \sim p$

Video: [The converse and inverse of a conditional statement](https://youtu.be/BNhp6LXncI0)

**The converse and inverse of a conditional statement:**
	The converse of the statement $p \rightarrow q$ is the statement $q \rightarrow p$.
	The inverse of the statement $p \rightarrow q$ is the statement $\sim p \rightarrow \sim q$.
	The converse and inverse are logically equivalent to each other but NOT logically equivalent to the original statement.

Video: [Biconditional Statements | "if and only if"](https://youtu.be/oHijygNdx_8)

**Biconditional statements:**
	The biconditional $p \leftrightarrow q$ means that both $p \rightarrow q$ and $q \rightarrow p$.

Video: [Logical Arguments - Modus Ponens & Modus Tollens](https://youtu.be/NTSZMdGlo4g)

**Logical arguments:**
	A valid argument is a list of premises from which the conclusion follows.

**Modus Ponens is an argument of the form:**
	if $p$, then $q$.
	$p$.
	Therefore, $q$.

**Modus Tollens is an argument of the form:**
	if $p$, then $q$.
	$\sim q$.
	Therefore, $\sim p$.

Video: [Logical Argument Forms: Generalizations, Specialization, Contradiction](https://youtu.be/pHWaxuyfK2s)

**Generalization is an argument of the form:**
	$p$.
	Therefore, $p \lor q$.

**Specialization is an argument of the form:**
	$p \land q$.
	Therefore, $p$.

**Contradiction is an argument of the form:**
	$\sim p \rightarrow c$.
	Therefore, $p$.

Video: [Analyzing an argument for validity](https://youtu.be/ON7yAw6W9VY)
Video: [Predicates and their Truth Sets]()

**Statements:**
	A statement is either TRUE or FALSE.
	Example: $3 > 2$ is TRUE

**Predicates:**
	A predicate is a sentence depending on variables which becomes a statement upon substituting values in the domain. The truth set of a predicate  is a set of all the values $x$ in the domain where $P(x)$ is TRUE.: $\{ x \in D | P(x)\}$
	Examples:
		$P(x)$: $x$ is a factor of 12 with domain $\mathbb{Z}^{+}$
		$P(6)$ is TRUE
		$P(5)$ is FALSE
		$P(\frac{1}{3})$ is nonsense! since $\frac{1}{3} \not \in \mathbb{Z}^{+}$
		The truth set of $P(x)$ is $TS = \{1,2,3,4,6,12\}$
		$TS \subseteq \mathbb{Z}^{+}$

Video: [Universal and Existential Quantifiers, ∀ "For All" and ∃ "There Exists"](https://youtu.be/GJpezCUMOxA)

**The Universal Quantifier $\forall$ means "for all":**
	Main use: "quantifying" predicates.
	$\forall x \in D, P(x)$
	For all $x$ in the domain $D$, $P(x)$ is TRUE.

**The Existential Quantifier $\exists$ means "there exists":**
	Main use: "quantifying" predicates.
	$\exists x \in D, P(x)$
	There exists $x$ in the domain, such that $P(x)$ is TRUE.

**Statements, predicates and quantifiers:**
	Logical statements are TRUE or FALSE, but predicates depend on the input variable. By putting a quantifier before a predicate it is turned into a logical statement.
	Statement: $P:$ "Roofus is a mammal"
	Predicate: $P(x):$ "$x$ is a mammal"
	Statement: $Q: \forall x \in D, P(x):$ "Every dog is a mammal

Video: [Negating Universal and Existential Quantifiers](https://youtu.be/q1rKFGSiZE8)

**Negating the Universal Quantifier:**
	$\sim ( \forall x \in D, P(x) ) \equiv \exists x \in D, \sim P(x)$

**Negating the Existential Quantifier:**
	$\sim ( \exists x \in D, P(x) ) \equiv \forall x \in D, \sim P(x)$

Video: [Negating Logical Statements with Multiple Quantifiers](Negating Logical Statements with Multiple Quantifiers)

**Negating Logical Statements with Multiple Quantifiers:**
	$\sim (\forall x \in D, \exists y \in D, y > x ) \equiv \exists x \in D, \forall y \in D, y \le x$
	$\sim ( \exists x \in D, \forall y \in D, x \ge y ) \equiv \forall x \in D, \exists y \in D, x < y$ 

Video: [Universal Conditionals P(x) implies Q(x)](https://youtu.be/4XrfeNIGUKM)

**Universal-Conditionals $P(x)$ implies $Q(x)$:**
	$P(x) \Rightarrow Q(x)$ means $\forall x \in D, P(x) \rightarrow Q(x)$

Video: [Necessary and Sufficient Conditions](https://youtu.be/KCMGWRoPuMY)

**Sufficient condition:**
	$A(x):$ $x$ is a square
	$B(x):$ $x$ is a rectangle
	"All squares are rectangles"
	Or written as: if $x$ is a square, then $x$ is a rectangle
	Or written as: If $A(x)$, then $B(x)$
	$A(x)$ is a sufficient condition for $B(x)$
	Or in other words: $x$ being a square is sufficient to conclude $x$ is a rectangle.

**Necessary condition (sufficient condition in the contrapositive form):**
	$B(x):$ $x$ is a rectangle
	$C(x):$ $x$ is a quadrilateral
	If $x$ is a rectangle, then $x$ is a quadrilateral
	Or written as: If $B(x)$, then $C(x)$
	The contrapositive is: If $x$ is not a quadrilateral then $x$ is not a rectangle
	Or written as: If $\sim C(x)$, then $\sim B(x)$
	$C(x)$ is a necessary condition for $B(x)$

**Nested conditions:**
	$A(x):$ $x$ is a square
	$B(x):$ $x$ is a rectangle
	$C(x):$ $x$ is a quadrilateral
	$A(x) \Rightarrow B(x) \Rightarrow C(x)$
	Sufficient to have $A(x)$ if we want $B(x)$ but necessary to have $C(x)$
	$A(x)$ is a sufficient condition for $B(x)$
	$B(x)$ is a necessary condition for $A(x)$

Video: [Formal Definitions in Math | Ex: Even & Odd Integers](https://youtu.be/dlKcfGu-WpI)

**Formal definitions:**
	Even integers:
		Informal definition: $n$ is an even integer if $n$ can be written as twice an integer.
		Formal definition: $n$ is an even integer if $\exists k \in \mathbb{Z}$ such that $n = 2k$.
	Odd integers:
		Informal definition: $n$ is an odd integer if $n$ is an integer that is not even.
		Formal definition: $n$ is an odd integer if $\exists k \in \mathbb{Z}$ such that $n = 2k + 1$

Video: [How to Prove Math Theorems | 1st Ex: Even + Odd = Odd](https://youtu.be/L74bnJWdHDo)

**Proving math theorems, "Even + odd = odd" direct proof example:**
	Theorem: 
		An even integer plus an odd integer is another odd integer.
	Proof:
		Suppose $m$ is even and $n$ is odd.
		$\exists k_1 \in \mathbb{Z}$ and $\exists k_2 \in \mathbb{Z}$ so that $m = 2k_1$ and $n = 2k_2 + 1$.
		Then, $m + n = (2k_1) + (2k_2 + 1) = 2(k_1 + k_2) + 1$
		Let $k_3 = k_1 + k_2$, and note it is an integer.
		Hence, $\exists k_3 \in \mathbb{Z}$ so that $m + n = 2k_3 + 1$
		Thus $m + n$ is odd. $\blacksquare$
	Structure in the proof:
		1) State the assumption
		2) Formally define the assumptions
		3) Manipulate
		4) Arrive at definition of conclusion
		5) State the conclusion

Video: [Step-By-Step Guide to Proofs | Ex: product of two evens is even](https://youtu.be/oqTg3D_jZWo)

**Proving math theorems, "Product of two evens is even" example:**
	Formal definition of an even number:
		For $n$ an integer: $n$ is even $\Leftrightarrow \exists k \in \mathbb{Z}$ such that $n = 2k$.
	Theorem:
		An even integer times an even integer is another even integer.
	Theorem stated formally:
		$\forall m, n \in \mathbb{Z}$, if $m$, $n$ are even, then $mn$ is even.
	Proof:
		Suppose $m$ and $n$ are even integers.
		As $m$, $n$ are even, $\exists r$ and $\exists s$ so that $m = 2r$ and $n = 2s$.
		Then,  $mn = (2r)(2s) = 2(2rs)$.
		Let $t=2rs$, and not it is an integer.
		Hence, $\exists t \in \mathbb{Z}$ so that $mn = 2t$.
		Thus $mn$ is even. $\blacksquare$
	Steps:
		1) Define terms
		2) State theorem formally
		3) Play around!
		4) Formal proof:
			1) Start with assumptions
			2) Apply definitions
			3) Manipulate
			4) Deduce conclusion

Video: [Rational Numbers | Definition + First Proof](https://youtu.be/JL2DXGFO8S8)

**Rational numbers definition:**
	Informal definition:
		$n$ is a rational number if it is a fraction. Ex: $\frac{3}{7}$
	Formal definition:
		$n$ is a rational number if $\exists p \in \mathbb{Z}, \exists q \in \mathbb{Z} \setminus \{0\}$ such that $n = \frac{p}{q}$
	Informal theorem:
		The sum of two rational numbers is another rational number.
	Formal theorem:
		...
	Proof:
		Suppose $m$ and $n$ are rational.
		$\exists p_1, p_2 \in \mathbb{Z}$ and $\exists q_1, q_2 \in \mathbb{Z} \setminus\{0\}$ so that $m = \frac{p_1}{q_1}$ and $n = \frac{p_2}{q_2}$
		Then, $m + n = \frac{p_1}{q_1} + \frac{p_2}{q_2} = \frac{p_1 q_2 + p_2 q_1}{q_1 q_2}$
		Let $p_3 = p_1 q_2 + p_2 q_1$ and $q_3 = q_1 q_2$
		Hence, $\exists p_3 \in \mathbb{Z}, \exists q_3 \in \mathbb{Z} \setminus\{0\}$ so $m + n = \frac{p_3}{q_3}$
		Thus $m + n$ is rational. $\blacksquare$

Video: [Proving that divisibility is transitive](https://youtu.be/F78_7Lv-7vM)

**Proving that divisibility is transitive:**
	Definition of divides:
		For $n$ and $d$ integers, $d \neq 0,\ \ d \mid n \ \ \Leftrightarrow \ \ \text{ if } \exists k \in \mathbb{Z} \text{ such that } n = dk$
		Other ways so say "$d$ divides $n$":
			$n$ is divisible by $d$
			$n$ is a multiple of $d$
			$d$ is a factor of $n$
	Theorem:
		If $a$ is divisible by $b,$ and $b$ is divisible by $c,$ then $a$ is divisible by $c.$
	Proof:
		Let $b \mid a$ and $c \mid b$
		$\exists \ s, t \in \mathbb{Z},\ a = st,\ b = tc$
		Then $a = sb = s(tc) = c(st)$ and $st \in \mathbb{Z}$
		$\Rightarrow c \mid a \ \ \blacksquare$

Video: [Disproving implications with Counterexamples](https://youtu.be/TcfVpnRRAvk)

**Disproving implications with Counterexamples:**
	Method of counterexample:
		Aim: to prove $P(x) \Rightarrow Q(x)$ is false
		Find one $a \in D$ where $P(a) \land \sim Q(a)$
	Example:
		Prove or disprove:
			For $a, b \in \mathbb{Z}, a^2 > b^2$ implies $a > b.$
		Proof:
			$(-4)^2 > 3^2$
			$16 > 9$
			$-4 < 3$
			So false by counterexample.

Video: [Proof by Division Into Cases](https://youtu.be/2A-EaY78bwc)

**Proof by Division Into Cases:**
	Method of division into cases:
		To prove $P(x) \lor Q(x) \Rightarrow R(x)$
		Case 1: $P(x) \Rightarrow R(x)$
		Case 2: $Q(x) \Rightarrow R(x)$
	Example:
		Theorem:
			The square of an integer has the same parity.
		Case 1: Assume $n$ is even
			$\exists k_1 \in \mathbb{Z}, n = 2k_1$
			So $n^2 = (2k_1)^2 = 2(2k_1^2)$
			Let $k_2 = 2k_1^2$
			So $n^2 = 2k_2$
			Thus $n^2$ is even.
		Case 2: Assume $n$ is odd
			$\exists k_1 \in \mathbb{Z}, n = 2k_1 + 1$
			So $n^2 = (2k_1 + 1)^2 = 2(2k_1^2 + 2k_1) + 1$
			Let $k_2 = 2k_1^2 + 2k_1$
			So $n^2 = 2k_2 + 1$
			Thus $n^2$ is even.

Video: [Proof by Contradiction | Method & First Example](https://youtu.be/huGWXh4l1M0)

**Proof by Contradiction:**
	Method of proof by contradiction:
		1. Suppose $\sim p$ is true.
		2. Get a contradiction like $0=1.$
		3. Therefore, $p$ is true.
	Example:
		Theorem:
			No integer is both even and odd.
		Proof:
			Theorem statement: $\forall n \in \mathbb{Z}, \sim (n \text{ is even  and } n \text{ is odd})$
			Negation of theorem: $\exists n \in \mathbb{Z}, n \text{ is even  and } n \text{ is odd}$
			so $\exists k_1, k_2 \in \mathbb{Z}, n = 2k_1, n=2k_2+1$
			$2k_1 = 2k_2 + 1 \ \ \Rightarrow \ \ 2(k_1-k_2) = 1$
			$\Rightarrow k_1 - k_2 = \frac{1}{2}$
			This is a contradiction, the difference of integers $k_1$ and $k_2$ should result in an integer.
			So no integer, is both even and odd. $\blacksquare$


Video: [Proof by Contrapositive | Method & First Example](https://youtu.be/0YqZIHFmVzg)

**Proof by Contrapositive:**
...

Video: [Quotient-Remainder Theorem and Modular Arithmetic](https://youtu.be/jCUOhbk1O_o)

**Quotient-Remainder Theorem:**
...

Video: [Proof: There are infinitely many primes numbers](https://youtu.be/inUkhh8-h-I)

**Proof: There are infinitely many prime numbers:**
...

Video: [Introduction to sequences](https://youtu.be/VG9ft4_dK24)
Video: [The formal definition of a sequence.](https://youtu.be/3kezO88rEvE)

**Sequences:**
...

Video: [The sum and product of finite sequences](https://youtu.be/q7jHR9ar1Fo)

**Sum and Product:**
...

Video: [Intro to Mathematical Induction](https://youtu.be/GdM_iA1Zek4)
Video: [Induction Proofs Involving Inequalities.](https://youtu.be/L5iCGi3dW-Y)
Video: [Strong Induction // Intro and Full Example](https://youtu.be/rfA0h9udl7E)
Video: [Recursive Sequences](https://youtu.be/0OcUAjOXmFc)
Video: [The Miraculous Fibonacci Sequence](https://youtu.be/qmm9GPhA1MY)
Video: [Prove A is a subset of B with the ELEMENT METHOD](https://youtu.be/3qzykhjtQzU)
Video: [Proving equalities of sets using the element method](https://youtu.be/oSV4qwO_kNY)
Video: [The union of two sets](https://youtu.be/EF3m9bSbtdI)
Video: [The Intersection of Two Sets](https://youtu.be/zEvQTK17xzY)
Video: [Universes and Complements in Set Theory](https://youtu.be/G4NLidjwbEA)
Video: [Using the Element Method to prove a Set Containment w/ Modus Tollens](https://youtu.be/CKuV0WxNVUU)
Video: [Power Sets and the Cardinality of the Continuum](https://youtu.be/-P1zMabaQi8)
Video: [Relations and their Inverses](https://youtu.be/cQiyDUiIcOQ)
Video: [Reflexive, Symmetric, and Transitive Relations on a Set](https://youtu.be/q0xN_N7l_Kw)
Video: [Equivalence Relations - Reflexive, Symmetric, and Transitive](https://youtu.be/T6RUxvJR8i4)
Video: [Intro to Graph Theory | Definitions & Ex: 7 Bridges of Konigsberg](https://youtu.be/C7YrMRdLkqo)
Video: [Properties in Graph Theory: Complete, Connected, Subgraph, Induced Subgraph](https://youtu.be/gC0RNpD2P1Y)
Video: [Degree of Vertices | Definition, Theorem & Example | Graph Theory](https://youtu.be/WTNBNSUhSTY)
Video: [Euler Paths & the 7 Bridges of Konigsberg | Graph Theory](https://youtu.be/dSK5jTEe-AM)
